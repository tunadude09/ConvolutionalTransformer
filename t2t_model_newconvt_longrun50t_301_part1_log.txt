nohup: ignoring input
WARNING: Logging before flag parsing goes to stderr.
W1023 16:54:27.687337 140280136558400 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1023 16:54:28.661285 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1023 16:54:29.771423 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W1023 16:54:29.773785 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W1023 16:54:29.773864 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:27: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W1023 16:54:29.773941 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:28: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

I1023 16:54:29.774179 140280136558400 usr_dir.py:43] Importing user module Language_Model_April2019_Restart from path /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements
W1023 16:54:29.777188 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W1023 16:54:29.777412 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W1023 16:54:29.795072 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_datagen.py:204: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

I1023 16:54:29.795195 140280136558400 t2t_datagen.py:207] Generating problems:
    translate:
      * translate_ende_wmt32k
W1023 16:54:29.795309 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_datagen.py:156: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

I1023 16:54:29.795640 140280136558400 t2t_datagen.py:280] Generating data for translate_ende_wmt32k.
W1023 16:54:29.795922 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/translate.py:170: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

I1023 16:54:29.795997 140280136558400 translate.py:172] Skipping compile data, found files:
/home/chrisf/t2t_datagen/translate_ende_wmt32k-compiled-train.lang1
/home/chrisf/t2t_datagen/translate_ende_wmt32k-compiled-train.lang2
I1023 16:54:29.796064 140280136558400 generator_utils.py:346] Found vocab file: /home/chrisf/t2t_data/vocab.translate_ende_wmt32k.32768.subwords
W1023 16:54:29.796137 140280136558400 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

I1023 16:54:29.868193 140280136558400 generator_utils.py:153] Skipping generator because outputs files exists at ['/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00000-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00001-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00002-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00003-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00004-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00005-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00006-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00007-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00008-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00009-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00010-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00011-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00012-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00013-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00014-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00015-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00016-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00017-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00018-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00019-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00020-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00021-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00022-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00023-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00024-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00025-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00026-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00027-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00028-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00029-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00030-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00031-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00032-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00033-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00034-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00035-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00036-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00037-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00038-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00039-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00040-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00041-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00042-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00043-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00044-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00045-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00046-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00047-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00048-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00049-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00050-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00051-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00052-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00053-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00054-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00055-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00056-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00057-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00058-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00059-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00060-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00061-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00062-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00063-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00064-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00065-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00066-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00067-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00068-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00069-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00070-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00071-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00072-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00073-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00074-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00075-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00076-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00077-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00078-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00079-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00080-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00081-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00082-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00083-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00084-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00085-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00086-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00087-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00088-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00089-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00090-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00091-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00092-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00093-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00094-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00095-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00096-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00097-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00098-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-train-00099-of-00100']
I1023 16:54:29.870578 140280136558400 translate.py:172] Skipping compile data, found files:
/home/chrisf/t2t_datagen/translate_ende_wmt32k-compiled-dev.lang1
/home/chrisf/t2t_datagen/translate_ende_wmt32k-compiled-dev.lang2
I1023 16:54:29.870676 140280136558400 generator_utils.py:346] Found vocab file: /home/chrisf/t2t_data/vocab.translate_ende_wmt32k.32768.subwords
I1023 16:54:29.940398 140280136558400 generator_utils.py:153] Skipping generator because outputs files exists at ['/home/chrisf/t2t_data/translate_ende_wmt32k-unshuffled-dev-00000-of-00001']
I1023 16:54:29.942502 140280136558400 generator_utils.py:527] Skipping shuffle because output files exist
WARNING: Logging before flag parsing goes to stderr.
W1023 16:54:31.044821 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1023 16:54:31.355962 140280393865024 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1023 16:54:32.797357 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W1023 16:54:32.797633 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W1023 16:54:32.809845 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.

W1023 16:54:32.810007 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

W1023 16:54:32.821563 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

W1023 16:54:32.844088 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W1023 16:54:32.854273 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.

W1023 16:54:32.862117 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow_gan/python/contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W1023 16:54:32.862219 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow_gan/python/contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.

W1023 16:54:33.250549 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W1023 16:54:33.250682 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W1023 16:54:33.250814 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

I1023 16:54:33.251110 140280393865024 usr_dir.py:43] Importing user module Language_Model_April2019_Restart from path /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements
I1023 16:54:33.253134 140280393865024 t2t_trainer.py:155] Found unparsed command-line arguments. Checking if any start with --hp_ and interpreting those as hparams settings.
W1023 16:54:33.253263 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py:165: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.

W1023 16:54:33.253304 140280393865024 t2t_trainer.py:165] Found unknown flag: --allow_growth=True
W1023 16:54:33.253562 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W1023 16:54:33.253672 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W1023 16:54:33.254234 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

W1023 16:54:33.254327 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

W1023 16:54:33.254423 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:242: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
I1023 16:54:33.254544 140280393865024 trainer_lib.py:265] Configuring DataParallelism to replicate the model.
I1023 16:54:33.254586 140280393865024 devices.py:76] schedule=train
I1023 16:54:33.254620 140280393865024 devices.py:77] worker_gpu=1
I1023 16:54:33.254652 140280393865024 devices.py:78] sync=False
W1023 16:54:33.254683 140280393865024 devices.py:141] Schedule=train. Assuming that training is running on a single machine.
I1023 16:54:33.254720 140280393865024 devices.py:170] datashard_devices: ['gpu:0']
I1023 16:54:33.254801 140280393865024 devices.py:171] caching_devices: None
I1023 16:54:33.254865 140280393865024 devices.py:172] ps_devices: ['gpu:0']
W1023 16:54:33.254980 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

I1023 16:54:33.325860 140280393865024 estimator.py:209] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f952fc65250>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: OFF
  }
}
isolate_session_state: true
, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f952fc65310>}
W1023 16:54:33.326035 140280393865024 model_fn.py:630] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f95306a2d40>) includes params argument, but params are not passed to Estimator.
W1023 16:54:33.335508 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I1023 16:54:33.345992 140280393865024 problem.py:644] Reading data files from /home/chrisf/t2t_data/translate_ende_wmt32k-train*
I1023 16:54:33.347177 140280393865024 problem.py:670] partition: 0 num_data_files: 100
W1023 16:54:33.348646 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W1023 16:54:33.381745 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
W1023 16:54:33.428565 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1023 16:54:33.455243 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/grouping.py:193: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1023 16:54:33.482907 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W1023 16:54:33.489386 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
I1023 16:54:33.522017 140280393865024 estimator.py:1145] Calling model_fn.
I1023 16:54:33.529359 140280393865024 t2t_model.py:2249] Setting T2TModel mode to 'train'
W1023 16:54:33.573862 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:244: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.

I1023 16:54:34.073742 140280393865024 api.py:255] Using variable initializer: uniform_unit_scaling
I1023 16:54:34.337710 140280393865024 t2t_model.py:2249] Transforming feature 'inputs' with symbol_modality_33510_1024.bottom
I1023 16:54:34.421318 140280393865024 t2t_model.py:2249] Transforming feature 'targets' with symbol_modality_33510_1024.targets_bottom
I1023 16:54:34.428987 140280393865024 t2t_model.py:2249] Building model body
W1023 16:54:34.469771 140280393865024 deprecation.py:506] From /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/Original_Transformer_T2TApril2019_evolve_2.py:3179: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W1023 16:54:34.496905 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.

W1023 16:54:34.858096 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/layers/common_attention.py:1249: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

I1023 16:54:39.575485 140280393865024 t2t_model.py:2249] Transforming body output with symbol_modality_33510_1024.top
W1023 16:54:39.643643 140280393865024 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

I1023 16:54:39.644996 140280393865024 learning_rate.py:29] Base learning rate: 0.100000
I1023 16:54:39.652022 140280393865024 optimize.py:338] Trainable Variables Total size: 191723520
I1023 16:54:39.652226 140280393865024 optimize.py:338] Non-trainable variables Total size: 5
I1023 16:54:39.652409 140280393865024 optimize.py:193] Using optimizer adam
I1023 16:54:48.106600 140280393865024 estimator.py:1147] Done calling model_fn.
I1023 16:54:48.107501 140280393865024 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I1023 16:54:51.153751 140280393865024 monitored_session.py:240] Graph was finalized.
2019-10-23 16:54:51.153989: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-10-23 16:54:51.175525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-10-23 16:54:51.176541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5601e91e8200 executing computations on platform Host. Devices:
2019-10-23 16:54:51.176558: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-23 16:54:51.177296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-23 16:54:51.198116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.198467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 16:54:51.198594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 16:54:51.199519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 16:54:51.200439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 16:54:51.200597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 16:54:51.201503: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 16:54:51.201970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 16:54:51.203908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 16:54:51.203990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.204378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.204681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 16:54:51.204707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 16:54:51.267230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 16:54:51.267263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 16:54:51.267269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 16:54:51.267389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.268081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.268410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 16:54:51.268703: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-10-23 16:54:51.268724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10460 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-10-23 16:54:51.269756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5601fadaa1f0 executing computations on platform CUDA. Devices:
2019-10-23 16:54:51.269769: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-10-23 16:54:53.899378: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I1023 16:54:55.540382 140280393865024 session_manager.py:500] Running local_init_op.
I1023 16:54:55.771474 140280393865024 session_manager.py:502] Done running local_init_op.
I1023 16:55:04.422729 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
2019-10-23 16:55:20.852677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 16:55:22.978666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
I1023 16:55:24.655769 140280393865024 basic_session_run_hooks.py:262] loss = 9.684053, step = 0
I1023 16:56:12.384289 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.09516
I1023 16:56:12.385036 140280393865024 basic_session_run_hooks.py:260] loss = 8.14319, step = 100 (47.729 sec)
I1023 16:56:50.231903 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64217
I1023 16:56:50.232504 140280393865024 basic_session_run_hooks.py:260] loss = 7.5158277, step = 200 (37.847 sec)
I1023 16:57:27.674047 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67079
I1023 16:57:27.674798 140280393865024 basic_session_run_hooks.py:260] loss = 7.0681643, step = 300 (37.442 sec)
I1023 16:58:06.756146 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.55872
I1023 16:58:06.756846 140280393865024 basic_session_run_hooks.py:260] loss = 6.76409, step = 400 (39.082 sec)
I1023 16:58:44.543064 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64641
I1023 16:58:44.543849 140280393865024 basic_session_run_hooks.py:260] loss = 6.577006, step = 500 (37.787 sec)
I1023 16:59:22.404128 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64124
I1023 16:59:22.404796 140280393865024 basic_session_run_hooks.py:260] loss = 6.6931977, step = 600 (37.861 sec)
2019-10-23 16:59:22.645462: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 16:59:22.646315: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 16:59:22.655617: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 16:59:22.655671: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
I1023 17:00:00.303254 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63858
I1023 17:00:00.303902 140280393865024 basic_session_run_hooks.py:260] loss = 6.5935507, step = 700 (37.899 sec)
2019-10-23 17:00:19.283009: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 17:00:19.283051: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 17:00:19.292037: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 17:00:19.292067: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 17:00:19.298706: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-23 17:00:19.298731: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
I1023 17:00:37.992698 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65326
I1023 17:00:37.993323 140280393865024 basic_session_run_hooks.py:260] loss = 6.496001, step = 800 (37.689 sec)
I1023 17:01:15.811613 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64418
I1023 17:01:15.812536 140280393865024 basic_session_run_hooks.py:260] loss = 6.322398, step = 900 (37.819 sec)
I1023 17:01:54.008314 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.61803
I1023 17:01:54.009065 140280393865024 basic_session_run_hooks.py:260] loss = 6.2927055, step = 1000 (38.197 sec)
I1023 17:02:31.380969 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67575
I1023 17:02:31.381772 140280393865024 basic_session_run_hooks.py:260] loss = 6.5046334, step = 1100 (37.373 sec)
I1023 17:03:09.203754 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64391
I1023 17:03:09.204370 140280393865024 basic_session_run_hooks.py:260] loss = 6.1088634, step = 1200 (37.823 sec)
I1023 17:03:47.031951 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64353
I1023 17:03:47.032928 140280393865024 basic_session_run_hooks.py:260] loss = 5.88489, step = 1300 (37.829 sec)
I1023 17:04:24.752033 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65111
I1023 17:04:24.752754 140280393865024 basic_session_run_hooks.py:260] loss = 5.9273663, step = 1400 (37.720 sec)
I1023 17:05:02.376448 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65785
I1023 17:05:02.377233 140280393865024 basic_session_run_hooks.py:260] loss = 5.757375, step = 1500 (37.624 sec)
I1023 17:05:12.598335 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 1528 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
2019-10-23 17:05:40.525548: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.21G (2378029312 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-23 17:05:40.528205: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 1.99G (2140226304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-23 17:05:40.530529: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 1.79G (1926203648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-23 17:05:40.532997: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 1.61G (1733583360 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-23 17:05:40.535382: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 1.45G (1560225024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
I1023 17:05:50.590131 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.0741
I1023 17:05:50.590799 140280393865024 basic_session_run_hooks.py:260] loss = 4.453164, step = 1600 (48.214 sec)
I1023 17:06:28.255080 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65499
I1023 17:06:28.255930 140280393865024 basic_session_run_hooks.py:260] loss = 5.491195, step = 1700 (37.665 sec)
I1023 17:07:05.994062 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64978
I1023 17:07:05.994704 140280393865024 basic_session_run_hooks.py:260] loss = 5.4822607, step = 1800 (37.739 sec)
I1023 17:07:43.814084 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6441
I1023 17:07:43.814776 140280393865024 basic_session_run_hooks.py:260] loss = 5.285383, step = 1900 (37.820 sec)
I1023 17:08:21.769795 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63465
I1023 17:08:21.770496 140280393865024 basic_session_run_hooks.py:260] loss = 5.7841024, step = 2000 (37.956 sec)
I1023 17:08:59.568367 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6456
I1023 17:08:59.569076 140280393865024 basic_session_run_hooks.py:260] loss = 5.3831086, step = 2100 (37.799 sec)
I1023 17:09:37.214601 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65631
I1023 17:09:37.215313 140280393865024 basic_session_run_hooks.py:260] loss = 5.4400644, step = 2200 (37.646 sec)
I1023 17:10:15.051980 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64289
I1023 17:10:15.053046 140280393865024 basic_session_run_hooks.py:260] loss = 5.3203673, step = 2300 (37.838 sec)
I1023 17:10:53.111241 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62748
I1023 17:10:53.112148 140280393865024 basic_session_run_hooks.py:260] loss = 6.2814345, step = 2400 (38.059 sec)
I1023 17:11:30.836140 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65077
I1023 17:11:30.836856 140280393865024 basic_session_run_hooks.py:260] loss = 5.180779, step = 2500 (37.725 sec)
I1023 17:12:08.775187 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63581
I1023 17:12:08.776018 140280393865024 basic_session_run_hooks.py:260] loss = 4.933745, step = 2600 (37.939 sec)
I1023 17:12:46.947494 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6197
I1023 17:12:46.948226 140280393865024 basic_session_run_hooks.py:260] loss = 5.030586, step = 2700 (38.172 sec)
I1023 17:13:24.901732 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63475
I1023 17:13:24.902397 140280393865024 basic_session_run_hooks.py:260] loss = 4.7520323, step = 2800 (37.954 sec)
I1023 17:14:02.703237 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6454
I1023 17:14:02.703937 140280393865024 basic_session_run_hooks.py:260] loss = 4.8081846, step = 2900 (37.802 sec)
I1023 17:14:40.730630 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62969
I1023 17:14:40.731390 140280393865024 basic_session_run_hooks.py:260] loss = 4.9957523, step = 3000 (38.027 sec)
I1023 17:15:12.907535 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 3086 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 17:15:25.512223 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.23306
I1023 17:15:25.512854 140280393865024 basic_session_run_hooks.py:260] loss = 4.7095385, step = 3100 (44.781 sec)
I1023 17:16:03.499500 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63246
I1023 17:16:03.500187 140280393865024 basic_session_run_hooks.py:260] loss = 5.090192, step = 3200 (37.987 sec)
I1023 17:16:41.058087 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66251
I1023 17:16:41.058688 140280393865024 basic_session_run_hooks.py:260] loss = 4.677314, step = 3300 (37.559 sec)
I1023 17:17:18.671030 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65866
I1023 17:17:18.672008 140280393865024 basic_session_run_hooks.py:260] loss = 4.9639983, step = 3400 (37.613 sec)
I1023 17:17:56.310702 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65677
I1023 17:17:56.311418 140280393865024 basic_session_run_hooks.py:260] loss = 4.9103117, step = 3500 (37.639 sec)
I1023 17:18:34.054402 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64945
I1023 17:18:34.055131 140280393865024 basic_session_run_hooks.py:260] loss = 4.2762914, step = 3600 (37.744 sec)
I1023 17:19:11.904741 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64198
I1023 17:19:11.905386 140280393865024 basic_session_run_hooks.py:260] loss = 4.4324217, step = 3700 (37.850 sec)
I1023 17:19:49.487896 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66077
I1023 17:19:49.488614 140280393865024 basic_session_run_hooks.py:260] loss = 4.4404206, step = 3800 (37.583 sec)
I1023 17:20:27.163578 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65423
I1023 17:20:27.164240 140280393865024 basic_session_run_hooks.py:260] loss = 4.9552236, step = 3900 (37.676 sec)
I1023 17:21:05.039157 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64022
I1023 17:21:05.040153 140280393865024 basic_session_run_hooks.py:260] loss = 5.1448555, step = 4000 (37.876 sec)
I1023 17:21:42.741847 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65233
I1023 17:21:42.742617 140280393865024 basic_session_run_hooks.py:260] loss = 4.476901, step = 4100 (37.702 sec)
I1023 17:22:20.424042 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65377
I1023 17:22:20.424807 140280393865024 basic_session_run_hooks.py:260] loss = 4.0269394, step = 4200 (37.682 sec)
I1023 17:22:58.133054 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65189
I1023 17:22:58.133689 140280393865024 basic_session_run_hooks.py:260] loss = 3.5172062, step = 4300 (37.709 sec)
I1023 17:23:35.694139 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66233
I1023 17:23:35.694849 140280393865024 basic_session_run_hooks.py:260] loss = 4.083695, step = 4400 (37.561 sec)
I1023 17:24:13.707894 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63063
I1023 17:24:13.708656 140280393865024 basic_session_run_hooks.py:260] loss = 4.3623877, step = 4500 (38.014 sec)
I1023 17:24:51.447982 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6497
I1023 17:24:51.448974 140280393865024 basic_session_run_hooks.py:260] loss = 4.7477603, step = 4600 (37.740 sec)
I1023 17:25:13.260013 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 4659 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 17:25:36.521802 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.21858
I1023 17:25:36.522659 140280393865024 basic_session_run_hooks.py:260] loss = 4.667088, step = 4700 (45.074 sec)
I1023 17:26:14.199631 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65408
I1023 17:26:14.200371 140280393865024 basic_session_run_hooks.py:260] loss = 5.0061507, step = 4800 (37.678 sec)
I1023 17:26:51.896971 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65271
I1023 17:26:51.897686 140280393865024 basic_session_run_hooks.py:260] loss = 4.2704525, step = 4900 (37.697 sec)
I1023 17:27:29.520193 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65793
I1023 17:27:29.520893 140280393865024 basic_session_run_hooks.py:260] loss = 4.460958, step = 5000 (37.623 sec)
I1023 17:28:07.187137 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65485
I1023 17:28:07.187931 140280393865024 basic_session_run_hooks.py:260] loss = 3.86573, step = 5100 (37.667 sec)
I1023 17:28:45.070103 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63971
I1023 17:28:45.070870 140280393865024 basic_session_run_hooks.py:260] loss = 3.3385093, step = 5200 (37.883 sec)
I1023 17:29:22.910508 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64268
I1023 17:29:22.911161 140280393865024 basic_session_run_hooks.py:260] loss = 3.7522867, step = 5300 (37.840 sec)
I1023 17:30:00.683510 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64739
I1023 17:30:00.684421 140280393865024 basic_session_run_hooks.py:260] loss = 4.206043, step = 5400 (37.773 sec)
I1023 17:30:38.270296 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66051
I1023 17:30:38.271120 140280393865024 basic_session_run_hooks.py:260] loss = 3.80183, step = 5500 (37.587 sec)
I1023 17:31:16.241967 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63354
I1023 17:31:16.242685 140280393865024 basic_session_run_hooks.py:260] loss = 4.4553485, step = 5600 (37.972 sec)
I1023 17:31:53.771152 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66459
I1023 17:31:53.772063 140280393865024 basic_session_run_hooks.py:260] loss = 4.210245, step = 5700 (37.529 sec)
I1023 17:32:31.599712 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64351
I1023 17:32:31.600482 140280393865024 basic_session_run_hooks.py:260] loss = 4.4514456, step = 5800 (37.828 sec)
I1023 17:33:09.420570 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64404
I1023 17:33:09.421243 140280393865024 basic_session_run_hooks.py:260] loss = 4.288599, step = 5900 (37.821 sec)
I1023 17:33:47.275321 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64168
I1023 17:33:47.276158 140280393865024 basic_session_run_hooks.py:260] loss = 4.2085385, step = 6000 (37.855 sec)
I1023 17:34:25.197416 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63699
I1023 17:34:25.198111 140280393865024 basic_session_run_hooks.py:260] loss = 3.4635222, step = 6100 (37.922 sec)
I1023 17:35:02.661003 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66926
I1023 17:35:02.661725 140280393865024 basic_session_run_hooks.py:260] loss = 3.3131588, step = 6200 (37.464 sec)
I1023 17:35:13.384260 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 6230 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 17:35:47.091705 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.2507
I1023 17:35:47.092428 140280393865024 basic_session_run_hooks.py:260] loss = 4.2614784, step = 6300 (44.431 sec)
I1023 17:36:24.840575 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64909
I1023 17:36:24.841176 140280393865024 basic_session_run_hooks.py:260] loss = 3.168738, step = 6400 (37.749 sec)
I1023 17:37:02.936125 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62498
I1023 17:37:02.936922 140280393865024 basic_session_run_hooks.py:260] loss = 3.4104733, step = 6500 (38.096 sec)
I1023 17:37:40.698929 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64811
I1023 17:37:40.699763 140280393865024 basic_session_run_hooks.py:260] loss = 3.6363845, step = 6600 (37.763 sec)
I1023 17:38:18.781086 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6259
I1023 17:38:18.781661 140280393865024 basic_session_run_hooks.py:260] loss = 3.2536707, step = 6700 (38.082 sec)
I1023 17:38:56.694317 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6376
I1023 17:38:56.694941 140280393865024 basic_session_run_hooks.py:260] loss = 3.4265316, step = 6800 (37.913 sec)
I1023 17:39:34.431263 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64992
I1023 17:39:34.431992 140280393865024 basic_session_run_hooks.py:260] loss = 3.4450629, step = 6900 (37.737 sec)
I1023 17:40:12.052287 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65809
I1023 17:40:12.053020 140280393865024 basic_session_run_hooks.py:260] loss = 3.2467573, step = 7000 (37.621 sec)
I1023 17:40:49.867673 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64443
I1023 17:40:49.868650 140280393865024 basic_session_run_hooks.py:260] loss = 4.9734883, step = 7100 (37.816 sec)
I1023 17:41:27.325664 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66966
I1023 17:41:27.326366 140280393865024 basic_session_run_hooks.py:260] loss = 3.1999338, step = 7200 (37.458 sec)
I1023 17:42:04.887843 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66225
I1023 17:42:04.888619 140280393865024 basic_session_run_hooks.py:260] loss = 3.2960095, step = 7300 (37.562 sec)
I1023 17:42:42.697358 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64484
I1023 17:42:42.698224 140280393865024 basic_session_run_hooks.py:260] loss = 3.6473753, step = 7400 (37.810 sec)
I1023 17:43:20.519495 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64395
I1023 17:43:20.520316 140280393865024 basic_session_run_hooks.py:260] loss = 4.5127606, step = 7500 (37.822 sec)
I1023 17:43:58.293273 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64734
I1023 17:43:58.293941 140280393865024 basic_session_run_hooks.py:260] loss = 3.1758213, step = 7600 (37.774 sec)
I1023 17:44:36.123968 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64336
I1023 17:44:36.124592 140280393865024 basic_session_run_hooks.py:260] loss = 2.6679022, step = 7700 (37.831 sec)
I1023 17:45:13.566915 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 7800 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 17:45:21.073789 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.2247
I1023 17:45:21.074470 140280393865024 basic_session_run_hooks.py:260] loss = 3.3220706, step = 7800 (44.950 sec)
I1023 17:45:58.711224 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65693
I1023 17:45:58.711982 140280393865024 basic_session_run_hooks.py:260] loss = 3.552555, step = 7900 (37.638 sec)
I1023 17:46:36.650691 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63578
I1023 17:46:36.651431 140280393865024 basic_session_run_hooks.py:260] loss = 3.4682004, step = 8000 (37.939 sec)
I1023 17:47:14.563716 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63762
I1023 17:47:14.564544 140280393865024 basic_session_run_hooks.py:260] loss = 3.0233698, step = 8100 (37.913 sec)
I1023 17:47:52.094186 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6645
I1023 17:47:52.094893 140280393865024 basic_session_run_hooks.py:260] loss = 3.2235284, step = 8200 (37.530 sec)
I1023 17:48:30.072044 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63311
I1023 17:48:30.072722 140280393865024 basic_session_run_hooks.py:260] loss = 3.3834631, step = 8300 (37.978 sec)
I1023 17:49:07.784339 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65165
I1023 17:49:07.785132 140280393865024 basic_session_run_hooks.py:260] loss = 3.449117, step = 8400 (37.712 sec)
I1023 17:49:45.672363 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63936
I1023 17:49:45.673016 140280393865024 basic_session_run_hooks.py:260] loss = 3.5138502, step = 8500 (37.888 sec)
I1023 17:50:23.302966 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65741
I1023 17:50:23.303741 140280393865024 basic_session_run_hooks.py:260] loss = 3.6330655, step = 8600 (37.631 sec)
I1023 17:51:01.065353 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64814
I1023 17:51:01.065921 140280393865024 basic_session_run_hooks.py:260] loss = 3.5837314, step = 8700 (37.762 sec)
I1023 17:51:38.692727 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65764
I1023 17:51:38.693501 140280393865024 basic_session_run_hooks.py:260] loss = 3.7470539, step = 8800 (37.628 sec)
I1023 17:52:16.354344 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65522
I1023 17:52:16.355090 140280393865024 basic_session_run_hooks.py:260] loss = 4.0889773, step = 8900 (37.662 sec)
I1023 17:52:53.827544 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66857
I1023 17:52:53.828209 140280393865024 basic_session_run_hooks.py:260] loss = 3.3667898, step = 9000 (37.473 sec)
I1023 17:53:31.619086 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6461
I1023 17:53:31.619924 140280393865024 basic_session_run_hooks.py:260] loss = 3.2659736, step = 9100 (37.792 sec)
I1023 17:54:09.456310 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6429
I1023 17:54:09.457038 140280393865024 basic_session_run_hooks.py:260] loss = 3.476217, step = 9200 (37.837 sec)
I1023 17:54:47.159324 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65231
I1023 17:54:47.160082 140280393865024 basic_session_run_hooks.py:260] loss = 4.505559, step = 9300 (37.703 sec)
I1023 17:55:13.822712 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 9371 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 17:55:33.448346 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.16034
I1023 17:55:33.449062 140280393865024 basic_session_run_hooks.py:260] loss = 3.5765212, step = 9400 (46.289 sec)
I1023 17:56:11.267748 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64415
I1023 17:56:11.268600 140280393865024 basic_session_run_hooks.py:260] loss = 3.5692022, step = 9500 (37.820 sec)
I1023 17:56:49.115495 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64216
I1023 17:56:49.116144 140280393865024 basic_session_run_hooks.py:260] loss = 3.3494704, step = 9600 (37.848 sec)
I1023 17:57:26.749179 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65719
I1023 17:57:26.749834 140280393865024 basic_session_run_hooks.py:260] loss = 3.1903434, step = 9700 (37.634 sec)
I1023 17:58:04.533083 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64663
I1023 17:58:04.533694 140280393865024 basic_session_run_hooks.py:260] loss = 3.0052643, step = 9800 (37.784 sec)
I1023 17:58:42.439694 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63806
I1023 17:58:42.440399 140280393865024 basic_session_run_hooks.py:260] loss = 3.7713215, step = 9900 (37.907 sec)
I1023 17:59:20.286180 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64225
I1023 17:59:20.287042 140280393865024 basic_session_run_hooks.py:260] loss = 3.7429984, step = 10000 (37.847 sec)
I1023 17:59:58.181200 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63887
I1023 17:59:58.181970 140280393865024 basic_session_run_hooks.py:260] loss = 3.4705863, step = 10100 (37.895 sec)
I1023 18:00:36.008947 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64356
I1023 18:00:36.009699 140280393865024 basic_session_run_hooks.py:260] loss = 3.1694539, step = 10200 (37.828 sec)
I1023 18:01:13.533268 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66494
I1023 18:01:13.533878 140280393865024 basic_session_run_hooks.py:260] loss = 3.2874634, step = 10300 (37.524 sec)
I1023 18:01:51.293853 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64826
I1023 18:01:51.294492 140280393865024 basic_session_run_hooks.py:260] loss = 2.7863226, step = 10400 (37.761 sec)
I1023 18:02:29.059848 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64788
I1023 18:02:29.060867 140280393865024 basic_session_run_hooks.py:260] loss = 4.327266, step = 10500 (37.766 sec)
I1023 18:03:06.681177 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65807
I1023 18:03:06.681782 140280393865024 basic_session_run_hooks.py:260] loss = 4.1932755, step = 10600 (37.621 sec)
I1023 18:03:44.487462 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64506
I1023 18:03:44.488263 140280393865024 basic_session_run_hooks.py:260] loss = 4.219708, step = 10700 (37.806 sec)
I1023 18:04:22.316363 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64348
I1023 18:04:22.317148 140280393865024 basic_session_run_hooks.py:260] loss = 3.6429846, step = 10800 (37.829 sec)
I1023 18:05:00.164877 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64211
I1023 18:05:00.165635 140280393865024 basic_session_run_hooks.py:260] loss = 4.5812664, step = 10900 (37.848 sec)
I1023 18:05:13.837107 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 10937 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:05:45.700256 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.1961
I1023 18:05:45.701246 140280393865024 basic_session_run_hooks.py:260] loss = 4.547387, step = 11000 (45.536 sec)
I1023 18:06:23.157922 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66968
I1023 18:06:23.158589 140280393865024 basic_session_run_hooks.py:260] loss = 3.716719, step = 11100 (37.457 sec)
I1023 18:07:00.876093 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65124
I1023 18:07:00.876932 140280393865024 basic_session_run_hooks.py:260] loss = 4.0599794, step = 11200 (37.718 sec)
I1023 18:07:38.476910 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65952
I1023 18:07:38.477591 140280393865024 basic_session_run_hooks.py:260] loss = 3.7540061, step = 11300 (37.601 sec)
I1023 18:08:16.529814 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62792
I1023 18:08:16.530591 140280393865024 basic_session_run_hooks.py:260] loss = 3.5113943, step = 11400 (38.053 sec)
I1023 18:08:54.362894 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64319
I1023 18:08:54.363614 140280393865024 basic_session_run_hooks.py:260] loss = 3.7390857, step = 11500 (37.833 sec)
I1023 18:09:32.223115 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6413
I1023 18:09:32.224184 140280393865024 basic_session_run_hooks.py:260] loss = 5.0274553, step = 11600 (37.861 sec)
I1023 18:10:09.837211 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65858
I1023 18:10:09.837862 140280393865024 basic_session_run_hooks.py:260] loss = 4.12668, step = 11700 (37.614 sec)
I1023 18:10:47.578753 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6496
I1023 18:10:47.579796 140280393865024 basic_session_run_hooks.py:260] loss = 4.15385, step = 11800 (37.742 sec)
I1023 18:11:25.427640 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64208
I1023 18:11:25.428321 140280393865024 basic_session_run_hooks.py:260] loss = 4.3034115, step = 11900 (37.849 sec)
I1023 18:12:03.107008 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65397
I1023 18:12:03.107862 140280393865024 basic_session_run_hooks.py:260] loss = 4.512095, step = 12000 (37.680 sec)
I1023 18:12:41.121877 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63055
I1023 18:12:41.122656 140280393865024 basic_session_run_hooks.py:260] loss = 3.3609135, step = 12100 (38.015 sec)
I1023 18:13:19.099851 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6331
I1023 18:13:19.100708 140280393865024 basic_session_run_hooks.py:260] loss = 3.755043, step = 12200 (37.978 sec)
I1023 18:13:56.940716 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64265
I1023 18:13:56.941367 140280393865024 basic_session_run_hooks.py:260] loss = 4.3932014, step = 12300 (37.841 sec)
I1023 18:14:34.443136 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66649
I1023 18:14:34.443912 140280393865024 basic_session_run_hooks.py:260] loss = 4.552776, step = 12400 (37.503 sec)
I1023 18:15:12.363916 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63708
I1023 18:15:12.364540 140280393865024 basic_session_run_hooks.py:260] loss = 4.49221, step = 12500 (37.921 sec)
I1023 18:15:13.838038 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 12505 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:16:00.723095 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.06786
I1023 18:16:00.723814 140280393865024 basic_session_run_hooks.py:260] loss = 4.1826186, step = 12600 (48.359 sec)
I1023 18:16:38.540381 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64429
I1023 18:16:38.540985 140280393865024 basic_session_run_hooks.py:260] loss = 4.2310104, step = 12700 (37.817 sec)
I1023 18:17:16.194658 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65574
I1023 18:17:16.195437 140280393865024 basic_session_run_hooks.py:260] loss = 4.217388, step = 12800 (37.654 sec)
I1023 18:17:53.751904 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6626
I1023 18:17:53.752719 140280393865024 basic_session_run_hooks.py:260] loss = 4.4338713, step = 12900 (37.557 sec)
I1023 18:18:31.738266 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63252
I1023 18:18:31.739125 140280393865024 basic_session_run_hooks.py:260] loss = 4.3252306, step = 13000 (37.986 sec)
I1023 18:19:09.617091 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64
I1023 18:19:09.617848 140280393865024 basic_session_run_hooks.py:260] loss = 4.5590005, step = 13100 (37.879 sec)
I1023 18:19:47.199473 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66082
I1023 18:19:47.200230 140280393865024 basic_session_run_hooks.py:260] loss = 4.003148, step = 13200 (37.582 sec)
I1023 18:20:24.659988 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66948
I1023 18:20:24.660681 140280393865024 basic_session_run_hooks.py:260] loss = 4.403947, step = 13300 (37.460 sec)
I1023 18:21:02.208555 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66322
I1023 18:21:02.209334 140280393865024 basic_session_run_hooks.py:260] loss = 4.2598796, step = 13400 (37.549 sec)
I1023 18:21:40.114432 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63811
I1023 18:21:40.115062 140280393865024 basic_session_run_hooks.py:260] loss = 4.928488, step = 13500 (37.906 sec)
I1023 18:22:17.772907 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65544
I1023 18:22:17.773538 140280393865024 basic_session_run_hooks.py:260] loss = 4.6798444, step = 13600 (37.658 sec)
I1023 18:22:55.379044 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65914
I1023 18:22:55.379758 140280393865024 basic_session_run_hooks.py:260] loss = 4.506886, step = 13700 (37.606 sec)
I1023 18:23:32.818572 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67097
I1023 18:23:32.819164 140280393865024 basic_session_run_hooks.py:260] loss = 4.2360754, step = 13800 (37.439 sec)
I1023 18:24:10.737424 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63721
I1023 18:24:10.738072 140280393865024 basic_session_run_hooks.py:260] loss = 4.587499, step = 13900 (37.919 sec)
I1023 18:24:48.466480 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65048
I1023 18:24:48.467184 140280393865024 basic_session_run_hooks.py:260] loss = 4.205336, step = 14000 (37.729 sec)
I1023 18:25:14.106265 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 14069 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:25:33.074673 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.24174
I1023 18:25:33.075920 140280393865024 basic_session_run_hooks.py:260] loss = 4.0049725, step = 14100 (44.609 sec)
I1023 18:26:10.506044 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67156
I1023 18:26:10.506819 140280393865024 basic_session_run_hooks.py:260] loss = 4.6925054, step = 14200 (37.431 sec)
I1023 18:26:48.683795 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.61933
I1023 18:26:48.684607 140280393865024 basic_session_run_hooks.py:260] loss = 5.126343, step = 14300 (38.178 sec)
I1023 18:27:26.207812 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66496
I1023 18:27:26.208631 140280393865024 basic_session_run_hooks.py:260] loss = 4.698169, step = 14400 (37.524 sec)
I1023 18:28:04.007449 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64553
I1023 18:28:04.008235 140280393865024 basic_session_run_hooks.py:260] loss = 4.755425, step = 14500 (37.800 sec)
I1023 18:28:41.614642 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65907
I1023 18:28:41.615372 140280393865024 basic_session_run_hooks.py:260] loss = 4.156525, step = 14600 (37.607 sec)
I1023 18:29:19.316168 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65241
I1023 18:29:19.316985 140280393865024 basic_session_run_hooks.py:260] loss = 4.6527805, step = 14700 (37.702 sec)
I1023 18:29:56.863240 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66332
I1023 18:29:56.863908 140280393865024 basic_session_run_hooks.py:260] loss = 4.9555893, step = 14800 (37.547 sec)
I1023 18:30:34.674663 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6447
I1023 18:30:34.675478 140280393865024 basic_session_run_hooks.py:260] loss = 4.683807, step = 14900 (37.812 sec)
I1023 18:31:12.852559 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.61932
I1023 18:31:12.853155 140280393865024 basic_session_run_hooks.py:260] loss = 4.0916996, step = 15000 (38.178 sec)
I1023 18:31:50.565186 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65163
I1023 18:31:50.566012 140280393865024 basic_session_run_hooks.py:260] loss = 4.658971, step = 15100 (37.713 sec)
I1023 18:32:28.250081 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65358
I1023 18:32:28.250746 140280393865024 basic_session_run_hooks.py:260] loss = 5.0727544, step = 15200 (37.685 sec)
I1023 18:33:05.876024 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65774
I1023 18:33:05.876703 140280393865024 basic_session_run_hooks.py:260] loss = 5.018714, step = 15300 (37.626 sec)
I1023 18:33:43.612281 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64997
I1023 18:33:43.613022 140280393865024 basic_session_run_hooks.py:260] loss = 5.1634398, step = 15400 (37.736 sec)
I1023 18:34:21.373166 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64824
I1023 18:34:21.373916 140280393865024 basic_session_run_hooks.py:260] loss = 4.6590986, step = 15500 (37.761 sec)
I1023 18:34:58.950511 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66118
I1023 18:34:58.951191 140280393865024 basic_session_run_hooks.py:260] loss = 5.1888113, step = 15600 (37.577 sec)
I1023 18:35:14.312041 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 15642 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:35:48.270756 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.02756
I1023 18:35:48.271393 140280393865024 basic_session_run_hooks.py:260] loss = 4.826805, step = 15700 (49.320 sec)
I1023 18:36:25.751179 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66806
I1023 18:36:25.751890 140280393865024 basic_session_run_hooks.py:260] loss = 4.1339693, step = 15800 (37.480 sec)
I1023 18:37:03.690061 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63582
I1023 18:37:03.690799 140280393865024 basic_session_run_hooks.py:260] loss = 5.4107037, step = 15900 (37.939 sec)
I1023 18:37:41.551473 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64121
I1023 18:37:41.552288 140280393865024 basic_session_run_hooks.py:260] loss = 5.038969, step = 16000 (37.861 sec)
I1023 18:38:19.268737 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6513
I1023 18:38:19.269448 140280393865024 basic_session_run_hooks.py:260] loss = 4.751312, step = 16100 (37.717 sec)
I1023 18:38:57.330639 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6273
I1023 18:38:57.331453 140280393865024 basic_session_run_hooks.py:260] loss = 5.1475716, step = 16200 (38.062 sec)
I1023 18:39:35.234139 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63828
I1023 18:39:35.234928 140280393865024 basic_session_run_hooks.py:260] loss = 5.010982, step = 16300 (37.903 sec)
I1023 18:40:12.802890 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66179
I1023 18:40:12.803584 140280393865024 basic_session_run_hooks.py:260] loss = 5.061136, step = 16400 (37.569 sec)
I1023 18:40:50.628724 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6437
I1023 18:40:50.629476 140280393865024 basic_session_run_hooks.py:260] loss = 5.0639644, step = 16500 (37.826 sec)
I1023 18:41:28.588393 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63438
I1023 18:41:28.589051 140280393865024 basic_session_run_hooks.py:260] loss = 5.096953, step = 16600 (37.960 sec)
I1023 18:42:06.492000 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63827
I1023 18:42:06.492775 140280393865024 basic_session_run_hooks.py:260] loss = 5.1696167, step = 16700 (37.904 sec)
I1023 18:42:44.041105 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66318
I1023 18:42:44.041711 140280393865024 basic_session_run_hooks.py:260] loss = 5.24065, step = 16800 (37.549 sec)
I1023 18:43:21.936931 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63881
I1023 18:43:21.937705 140280393865024 basic_session_run_hooks.py:260] loss = 5.4110246, step = 16900 (37.896 sec)
I1023 18:43:59.429148 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66722
I1023 18:43:59.430003 140280393865024 basic_session_run_hooks.py:260] loss = 4.8905225, step = 17000 (37.492 sec)
I1023 18:44:37.020035 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66022
I1023 18:44:37.020753 140280393865024 basic_session_run_hooks.py:260] loss = 5.08175, step = 17100 (37.591 sec)
I1023 18:45:14.613693 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 17201 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:45:21.132476 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.26693
I1023 18:45:21.133522 140280393865024 basic_session_run_hooks.py:260] loss = 5.137362, step = 17200 (44.113 sec)
I1023 18:45:58.847162 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65149
I1023 18:45:58.847963 140280393865024 basic_session_run_hooks.py:260] loss = 5.4608765, step = 17300 (37.714 sec)
I1023 18:46:36.679867 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64322
I1023 18:46:36.680646 140280393865024 basic_session_run_hooks.py:260] loss = 4.8874793, step = 17400 (37.833 sec)
I1023 18:47:14.230170 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6631
I1023 18:47:14.230789 140280393865024 basic_session_run_hooks.py:260] loss = 5.0649986, step = 17500 (37.550 sec)
I1023 18:47:51.979984 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64902
I1023 18:47:51.980774 140280393865024 basic_session_run_hooks.py:260] loss = 5.159523, step = 17600 (37.750 sec)
I1023 18:48:29.921624 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63563
I1023 18:48:29.922480 140280393865024 basic_session_run_hooks.py:260] loss = 5.417746, step = 17700 (37.942 sec)
I1023 18:49:07.735074 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64456
I1023 18:49:07.735867 140280393865024 basic_session_run_hooks.py:260] loss = 5.273017, step = 17800 (37.813 sec)
I1023 18:49:45.360401 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65778
I1023 18:49:45.361091 140280393865024 basic_session_run_hooks.py:260] loss = 5.5155644, step = 17900 (37.625 sec)
I1023 18:50:23.291880 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63633
I1023 18:50:23.292629 140280393865024 basic_session_run_hooks.py:260] loss = 5.248686, step = 18000 (37.932 sec)
I1023 18:51:00.800300 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66607
I1023 18:51:00.800939 140280393865024 basic_session_run_hooks.py:260] loss = 5.414395, step = 18100 (37.508 sec)
I1023 18:51:38.703111 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63833
I1023 18:51:38.703941 140280393865024 basic_session_run_hooks.py:260] loss = 5.3646154, step = 18200 (37.903 sec)
I1023 18:52:16.283373 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66097
I1023 18:52:16.284012 140280393865024 basic_session_run_hooks.py:260] loss = 4.696104, step = 18300 (37.580 sec)
I1023 18:52:53.984784 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65242
I1023 18:52:53.985526 140280393865024 basic_session_run_hooks.py:260] loss = 5.8766785, step = 18400 (37.702 sec)
I1023 18:53:31.771243 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64645
I1023 18:53:31.772057 140280393865024 basic_session_run_hooks.py:260] loss = 5.2346363, step = 18500 (37.787 sec)
I1023 18:54:09.499877 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65051
I1023 18:54:09.500542 140280393865024 basic_session_run_hooks.py:260] loss = 5.4828863, step = 18600 (37.728 sec)
I1023 18:54:47.131200 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65736
I1023 18:54:47.132067 140280393865024 basic_session_run_hooks.py:260] loss = 5.0037956, step = 18700 (37.632 sec)
I1023 18:55:14.624692 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 18773 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 18:55:32.570281 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.20075
I1023 18:55:32.571081 140280393865024 basic_session_run_hooks.py:260] loss = 6.1046953, step = 18800 (45.439 sec)
I1023 18:56:10.203098 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65726
I1023 18:56:10.204040 140280393865024 basic_session_run_hooks.py:260] loss = 5.781639, step = 18900 (37.633 sec)
I1023 18:56:47.801072 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65972
I1023 18:56:47.801764 140280393865024 basic_session_run_hooks.py:260] loss = 6.0959105, step = 19000 (37.598 sec)
I1023 18:57:25.505540 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65221
I1023 18:57:25.506317 140280393865024 basic_session_run_hooks.py:260] loss = 5.343847, step = 19100 (37.705 sec)
I1023 18:58:03.350747 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64234
I1023 18:58:03.351475 140280393865024 basic_session_run_hooks.py:260] loss = 5.166619, step = 19200 (37.845 sec)
I1023 18:58:41.008446 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6555
I1023 18:58:41.009067 140280393865024 basic_session_run_hooks.py:260] loss = 5.159977, step = 19300 (37.658 sec)
I1023 18:59:18.822657 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64451
I1023 18:59:18.823437 140280393865024 basic_session_run_hooks.py:260] loss = 5.4840593, step = 19400 (37.814 sec)
I1023 18:59:56.484928 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65518
I1023 18:59:56.485558 140280393865024 basic_session_run_hooks.py:260] loss = 5.5749288, step = 19500 (37.662 sec)
I1023 19:00:34.197607 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65163
I1023 19:00:34.198266 140280393865024 basic_session_run_hooks.py:260] loss = 5.372246, step = 19600 (37.713 sec)
I1023 19:01:11.927954 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65039
I1023 19:01:11.928773 140280393865024 basic_session_run_hooks.py:260] loss = 5.850347, step = 19700 (37.731 sec)
I1023 19:01:49.516045 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66042
I1023 19:01:49.516686 140280393865024 basic_session_run_hooks.py:260] loss = 5.05575, step = 19800 (37.588 sec)
I1023 19:02:27.354260 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64283
I1023 19:02:27.354874 140280393865024 basic_session_run_hooks.py:260] loss = 5.514116, step = 19900 (37.838 sec)
I1023 19:03:05.271267 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63734
I1023 19:03:05.271931 140280393865024 basic_session_run_hooks.py:260] loss = 4.7219234, step = 20000 (37.917 sec)
I1023 19:03:43.108005 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64293
I1023 19:03:43.108645 140280393865024 basic_session_run_hooks.py:260] loss = 6.0121336, step = 20100 (37.837 sec)
I1023 19:04:20.863716 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64861
I1023 19:04:20.864379 140280393865024 basic_session_run_hooks.py:260] loss = 5.3798056, step = 20200 (37.756 sec)
I1023 19:04:58.753333 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63925
I1023 19:04:58.754144 140280393865024 basic_session_run_hooks.py:260] loss = 5.497625, step = 20300 (37.890 sec)
I1023 19:05:14.994930 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 20344 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:05:46.861308 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.07866
I1023 19:05:46.861941 140280393865024 basic_session_run_hooks.py:260] loss = 5.584588, step = 20400 (48.108 sec)
I1023 19:06:24.886737 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62982
I1023 19:06:24.887335 140280393865024 basic_session_run_hooks.py:260] loss = 6.112646, step = 20500 (38.025 sec)
I1023 19:07:02.805225 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63724
I1023 19:07:02.806039 140280393865024 basic_session_run_hooks.py:260] loss = 5.8486614, step = 20600 (37.919 sec)
I1023 19:07:40.422273 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65837
I1023 19:07:40.423119 140280393865024 basic_session_run_hooks.py:260] loss = 5.8267536, step = 20700 (37.617 sec)
I1023 19:08:18.342511 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63711
I1023 19:08:18.343436 140280393865024 basic_session_run_hooks.py:260] loss = 5.586479, step = 20800 (37.920 sec)
I1023 19:08:55.868083 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66485
I1023 19:08:55.868790 140280393865024 basic_session_run_hooks.py:260] loss = 5.691864, step = 20900 (37.525 sec)
I1023 19:09:33.679805 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64468
I1023 19:09:33.680448 140280393865024 basic_session_run_hooks.py:260] loss = 6.205762, step = 21000 (37.812 sec)
I1023 19:10:11.448144 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64772
I1023 19:10:11.448996 140280393865024 basic_session_run_hooks.py:260] loss = 5.406035, step = 21100 (37.769 sec)
I1023 19:10:48.859041 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67302
I1023 19:10:48.860104 140280393865024 basic_session_run_hooks.py:260] loss = 5.6546793, step = 21200 (37.411 sec)
I1023 19:11:26.764520 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63814
I1023 19:11:26.765284 140280393865024 basic_session_run_hooks.py:260] loss = 5.583694, step = 21300 (37.905 sec)
I1023 19:12:04.483340 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6512
I1023 19:12:04.484114 140280393865024 basic_session_run_hooks.py:260] loss = 5.5050178, step = 21400 (37.719 sec)
I1023 19:12:42.542321 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6275
I1023 19:12:42.542960 140280393865024 basic_session_run_hooks.py:260] loss = 5.599731, step = 21500 (38.059 sec)
I1023 19:13:20.338386 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64578
I1023 19:13:20.339385 140280393865024 basic_session_run_hooks.py:260] loss = 5.7493706, step = 21600 (37.796 sec)
I1023 19:13:58.295647 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63454
I1023 19:13:58.296284 140280393865024 basic_session_run_hooks.py:260] loss = 5.9235272, step = 21700 (37.957 sec)
I1023 19:14:36.227823 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63628
I1023 19:14:36.228559 140280393865024 basic_session_run_hooks.py:260] loss = 5.9814944, step = 21800 (37.932 sec)
I1023 19:15:14.039195 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64471
I1023 19:15:14.039947 140280393865024 basic_session_run_hooks.py:260] loss = 5.559407, step = 21900 (37.811 sec)
I1023 19:15:15.179702 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 21904 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:15:58.912751 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.22848
I1023 19:15:58.913391 140280393865024 basic_session_run_hooks.py:260] loss = 6.0262294, step = 22000 (44.873 sec)
I1023 19:16:36.750778 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64285
I1023 19:16:36.751512 140280393865024 basic_session_run_hooks.py:260] loss = 5.97529, step = 22100 (37.838 sec)
I1023 19:17:14.445281 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65291
I1023 19:17:14.445962 140280393865024 basic_session_run_hooks.py:260] loss = 6.4906907, step = 22200 (37.694 sec)
I1023 19:17:52.320641 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64024
I1023 19:17:52.321275 140280393865024 basic_session_run_hooks.py:260] loss = 5.5208507, step = 22300 (37.875 sec)
I1023 19:18:30.326657 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63116
I1023 19:18:30.327353 140280393865024 basic_session_run_hooks.py:260] loss = 6.6798067, step = 22400 (38.006 sec)
I1023 19:19:08.037105 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65179
I1023 19:19:08.037830 140280393865024 basic_session_run_hooks.py:260] loss = 5.7215676, step = 22500 (37.710 sec)
I1023 19:19:45.516703 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66812
I1023 19:19:45.517421 140280393865024 basic_session_run_hooks.py:260] loss = 5.409108, step = 22600 (37.480 sec)
I1023 19:20:23.380009 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64108
I1023 19:20:23.380773 140280393865024 basic_session_run_hooks.py:260] loss = 5.9178424, step = 22700 (37.863 sec)
I1023 19:21:01.382621 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6314
I1023 19:21:01.383263 140280393865024 basic_session_run_hooks.py:260] loss = 5.8228583, step = 22800 (38.002 sec)
I1023 19:21:39.179052 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64575
I1023 19:21:39.179866 140280393865024 basic_session_run_hooks.py:260] loss = 5.904185, step = 22900 (37.797 sec)
I1023 19:22:16.848147 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6547
I1023 19:22:16.849075 140280393865024 basic_session_run_hooks.py:260] loss = 5.7339826, step = 23000 (37.669 sec)
I1023 19:22:54.382812 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6642
I1023 19:22:54.383499 140280393865024 basic_session_run_hooks.py:260] loss = 5.481742, step = 23100 (37.534 sec)
I1023 19:23:32.329437 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63528
I1023 19:23:32.330090 140280393865024 basic_session_run_hooks.py:260] loss = 5.740516, step = 23200 (37.947 sec)
I1023 19:24:10.179667 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64199
I1023 19:24:10.180393 140280393865024 basic_session_run_hooks.py:260] loss = 5.880127, step = 23300 (37.850 sec)
I1023 19:24:48.067092 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6394
I1023 19:24:48.068152 140280393865024 basic_session_run_hooks.py:260] loss = 6.2229924, step = 23400 (37.888 sec)
I1023 19:25:15.353475 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 23473 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:25:36.339768 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.07157
I1023 19:25:36.340605 140280393865024 basic_session_run_hooks.py:260] loss = 5.6790814, step = 23500 (48.272 sec)
I1023 19:26:14.403544 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62717
I1023 19:26:14.404285 140280393865024 basic_session_run_hooks.py:260] loss = 5.927729, step = 23600 (38.064 sec)
I1023 19:26:51.856419 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67002
I1023 19:26:51.857423 140280393865024 basic_session_run_hooks.py:260] loss = 5.7094374, step = 23700 (37.453 sec)
I1023 19:27:29.691079 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64308
I1023 19:27:29.691905 140280393865024 basic_session_run_hooks.py:260] loss = 5.586023, step = 23800 (37.834 sec)
I1023 19:28:07.475819 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64657
I1023 19:28:07.476646 140280393865024 basic_session_run_hooks.py:260] loss = 5.953443, step = 23900 (37.785 sec)
I1023 19:28:45.373683 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63867
I1023 19:28:45.374336 140280393865024 basic_session_run_hooks.py:260] loss = 5.780873, step = 24000 (37.898 sec)
I1023 19:29:23.330299 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63459
I1023 19:29:23.331017 140280393865024 basic_session_run_hooks.py:260] loss = 5.747211, step = 24100 (37.957 sec)
I1023 19:30:01.231658 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63843
I1023 19:30:01.232353 140280393865024 basic_session_run_hooks.py:260] loss = 5.9191213, step = 24200 (37.901 sec)
I1023 19:30:39.033192 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6454
I1023 19:30:39.033815 140280393865024 basic_session_run_hooks.py:260] loss = 4.7718987, step = 24300 (37.801 sec)
I1023 19:31:16.800999 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64776
I1023 19:31:16.801768 140280393865024 basic_session_run_hooks.py:260] loss = 5.8576765, step = 24400 (37.768 sec)
I1023 19:31:54.778439 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63314
I1023 19:31:54.779103 140280393865024 basic_session_run_hooks.py:260] loss = 5.065797, step = 24500 (37.977 sec)
I1023 19:32:32.191221 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67288
I1023 19:32:32.192042 140280393865024 basic_session_run_hooks.py:260] loss = 5.501971, step = 24600 (37.413 sec)
I1023 19:33:10.097138 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63811
I1023 19:33:10.097945 140280393865024 basic_session_run_hooks.py:260] loss = 5.868513, step = 24700 (37.906 sec)
I1023 19:33:48.049304 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6349
I1023 19:33:48.050174 140280393865024 basic_session_run_hooks.py:260] loss = 5.793707, step = 24800 (37.952 sec)
I1023 19:34:25.789218 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64971
I1023 19:34:25.789809 140280393865024 basic_session_run_hooks.py:260] loss = 5.623268, step = 24900 (37.740 sec)
I1023 19:35:03.519775 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65037
I1023 19:35:03.520436 140280393865024 basic_session_run_hooks.py:260] loss = 6.2602506, step = 25000 (37.731 sec)
I1023 19:35:15.657201 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 25033 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:35:49.111800 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.19337
I1023 19:35:49.112524 140280393865024 basic_session_run_hooks.py:260] loss = 5.7057548, step = 25100 (45.592 sec)
I1023 19:36:26.895130 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64667
I1023 19:36:26.896022 140280393865024 basic_session_run_hooks.py:260] loss = 5.79694, step = 25200 (37.783 sec)
I1023 19:37:04.571200 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6542
I1023 19:37:04.572101 140280393865024 basic_session_run_hooks.py:260] loss = 5.9173045, step = 25300 (37.676 sec)
I1023 19:37:42.120482 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66317
I1023 19:37:42.121128 140280393865024 basic_session_run_hooks.py:260] loss = 6.172714, step = 25400 (37.549 sec)
I1023 19:38:19.794808 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65433
I1023 19:38:19.795434 140280393865024 basic_session_run_hooks.py:260] loss = 5.9014926, step = 25500 (37.674 sec)
I1023 19:38:57.450774 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65562
I1023 19:38:57.451474 140280393865024 basic_session_run_hooks.py:260] loss = 5.529959, step = 25600 (37.656 sec)
I1023 19:39:35.375485 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6368
I1023 19:39:35.376163 140280393865024 basic_session_run_hooks.py:260] loss = 5.781521, step = 25700 (37.925 sec)
I1023 19:40:13.187829 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64464
I1023 19:40:13.188547 140280393865024 basic_session_run_hooks.py:260] loss = 5.9429574, step = 25800 (37.812 sec)
I1023 19:40:50.959032 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64752
I1023 19:40:50.959871 140280393865024 basic_session_run_hooks.py:260] loss = 5.995159, step = 25900 (37.771 sec)
I1023 19:41:28.919897 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63429
I1023 19:41:28.920701 140280393865024 basic_session_run_hooks.py:260] loss = 5.8292065, step = 26000 (37.961 sec)
I1023 19:42:06.858622 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63583
I1023 19:42:06.859483 140280393865024 basic_session_run_hooks.py:260] loss = 5.8467493, step = 26100 (37.939 sec)
I1023 19:42:44.780998 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63697
I1023 19:42:44.781768 140280393865024 basic_session_run_hooks.py:260] loss = 6.0480747, step = 26200 (37.922 sec)
I1023 19:43:23.062520 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.61223
I1023 19:43:23.063425 140280393865024 basic_session_run_hooks.py:260] loss = 5.469441, step = 26300 (38.282 sec)
I1023 19:44:01.277221 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.61679
I1023 19:44:01.277932 140280393865024 basic_session_run_hooks.py:260] loss = 5.8425274, step = 26400 (38.215 sec)
I1023 19:44:39.210429 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63621
I1023 19:44:39.211363 140280393865024 basic_session_run_hooks.py:260] loss = 5.6408935, step = 26500 (37.933 sec)
I1023 19:45:15.908951 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 26598 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:45:24.329411 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.21636
I1023 19:45:24.333646 140280393865024 basic_session_run_hooks.py:260] loss = 5.4142246, step = 26600 (45.122 sec)
I1023 19:46:01.830085 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66662
I1023 19:46:01.830881 140280393865024 basic_session_run_hooks.py:260] loss = 6.247551, step = 26700 (37.497 sec)
I1023 19:46:39.281249 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67014
I1023 19:46:39.281979 140280393865024 basic_session_run_hooks.py:260] loss = 6.001432, step = 26800 (37.451 sec)
I1023 19:47:16.877699 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65983
I1023 19:47:16.878427 140280393865024 basic_session_run_hooks.py:260] loss = 5.476546, step = 26900 (37.596 sec)
I1023 19:47:54.438525 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66235
I1023 19:47:54.439296 140280393865024 basic_session_run_hooks.py:260] loss = 5.585787, step = 27000 (37.561 sec)
I1023 19:48:31.955830 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66544
I1023 19:48:31.956653 140280393865024 basic_session_run_hooks.py:260] loss = 5.9095926, step = 27100 (37.517 sec)
I1023 19:49:09.502909 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66332
I1023 19:49:09.503803 140280393865024 basic_session_run_hooks.py:260] loss = 5.686973, step = 27200 (37.547 sec)
I1023 19:49:47.214084 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65173
I1023 19:49:47.214797 140280393865024 basic_session_run_hooks.py:260] loss = 6.1641684, step = 27300 (37.711 sec)
I1023 19:50:25.039049 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64376
I1023 19:50:25.039903 140280393865024 basic_session_run_hooks.py:260] loss = 6.0637665, step = 27400 (37.825 sec)
I1023 19:51:02.895171 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64158
I1023 19:51:02.895964 140280393865024 basic_session_run_hooks.py:260] loss = 5.7827663, step = 27500 (37.856 sec)
I1023 19:51:40.715422 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64409
I1023 19:51:40.716190 140280393865024 basic_session_run_hooks.py:260] loss = 6.124412, step = 27600 (37.820 sec)
I1023 19:52:18.344248 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65754
I1023 19:52:18.344891 140280393865024 basic_session_run_hooks.py:260] loss = 5.7654514, step = 27700 (37.629 sec)
I1023 19:52:56.191732 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64218
I1023 19:52:56.192542 140280393865024 basic_session_run_hooks.py:260] loss = 6.128374, step = 27800 (37.848 sec)
I1023 19:53:33.911135 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65116
I1023 19:53:33.911720 140280393865024 basic_session_run_hooks.py:260] loss = 5.914506, step = 27900 (37.719 sec)
I1023 19:54:11.773453 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64115
I1023 19:54:11.774179 140280393865024 basic_session_run_hooks.py:260] loss = 5.758982, step = 28000 (37.862 sec)
I1023 19:54:49.449631 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6542
I1023 19:54:49.450445 140280393865024 basic_session_run_hooks.py:260] loss = 5.873059, step = 28100 (37.676 sec)
I1023 19:55:16.192594 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 28172 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 19:55:35.055327 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.19271
I1023 19:55:35.055964 140280393865024 basic_session_run_hooks.py:260] loss = 6.2552023, step = 28200 (45.606 sec)
I1023 19:56:12.798275 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6495
I1023 19:56:12.799046 140280393865024 basic_session_run_hooks.py:260] loss = 5.1880484, step = 28300 (37.743 sec)
I1023 19:56:50.234940 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67118
I1023 19:56:50.235667 140280393865024 basic_session_run_hooks.py:260] loss = 5.9989247, step = 28400 (37.437 sec)
I1023 19:57:27.889450 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65572
I1023 19:57:27.890255 140280393865024 basic_session_run_hooks.py:260] loss = 5.5849237, step = 28500 (37.655 sec)
I1023 19:58:05.650901 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6482
I1023 19:58:05.651682 140280393865024 basic_session_run_hooks.py:260] loss = 5.9693027, step = 28600 (37.761 sec)
I1023 19:58:43.473407 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64393
I1023 19:58:43.474176 140280393865024 basic_session_run_hooks.py:260] loss = 5.976282, step = 28700 (37.822 sec)
I1023 19:59:21.151016 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6541
I1023 19:59:21.151933 140280393865024 basic_session_run_hooks.py:260] loss = 6.084699, step = 28800 (37.678 sec)
I1023 19:59:58.886469 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65003
I1023 19:59:58.887261 140280393865024 basic_session_run_hooks.py:260] loss = 5.672978, step = 28900 (37.735 sec)
I1023 20:00:36.619283 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65022
I1023 20:00:36.620208 140280393865024 basic_session_run_hooks.py:260] loss = 5.8306656, step = 29000 (37.733 sec)
I1023 20:01:14.516205 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63873
I1023 20:01:14.517010 140280393865024 basic_session_run_hooks.py:260] loss = 5.5752697, step = 29100 (37.897 sec)
I1023 20:01:52.208224 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65308
I1023 20:01:52.209032 140280393865024 basic_session_run_hooks.py:260] loss = 5.4378066, step = 29200 (37.692 sec)
I1023 20:02:29.612067 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67352
I1023 20:02:29.612778 140280393865024 basic_session_run_hooks.py:260] loss = 6.062523, step = 29300 (37.404 sec)
I1023 20:03:07.204103 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66014
I1023 20:03:07.205065 140280393865024 basic_session_run_hooks.py:260] loss = 5.4279113, step = 29400 (37.592 sec)
I1023 20:03:44.580998 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67545
I1023 20:03:44.581957 140280393865024 basic_session_run_hooks.py:260] loss = 5.6726213, step = 29500 (37.377 sec)
I1023 20:04:22.394627 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64455
I1023 20:04:22.395385 140280393865024 basic_session_run_hooks.py:260] loss = 5.4422083, step = 29600 (37.813 sec)
I1023 20:05:00.335130 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63571
I1023 20:05:00.335863 140280393865024 basic_session_run_hooks.py:260] loss = 5.857775, step = 29700 (37.940 sec)
I1023 20:05:16.505180 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 29744 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 20:05:47.226384 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.13259
I1023 20:05:47.227081 140280393865024 basic_session_run_hooks.py:260] loss = 6.0951376, step = 29800 (46.891 sec)
I1023 20:06:25.097581 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64053
I1023 20:06:25.098423 140280393865024 basic_session_run_hooks.py:260] loss = 5.6463513, step = 29900 (37.871 sec)
I1023 20:07:02.789859 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65306
I1023 20:07:02.790682 140280393865024 basic_session_run_hooks.py:260] loss = 5.8964615, step = 30000 (37.692 sec)
I1023 20:07:40.352933 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66219
I1023 20:07:40.353539 140280393865024 basic_session_run_hooks.py:260] loss = 5.8213463, step = 30100 (37.563 sec)
I1023 20:08:18.169096 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64437
I1023 20:08:18.169720 140280393865024 basic_session_run_hooks.py:260] loss = 5.1362333, step = 30200 (37.816 sec)
I1023 20:08:55.695260 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66481
I1023 20:08:55.696069 140280393865024 basic_session_run_hooks.py:260] loss = 5.9210277, step = 30300 (37.526 sec)
I1023 20:09:33.387333 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65308
I1023 20:09:33.388040 140280393865024 basic_session_run_hooks.py:260] loss = 6.1294107, step = 30400 (37.692 sec)
I1023 20:10:10.890386 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66645
I1023 20:10:10.891341 140280393865024 basic_session_run_hooks.py:260] loss = 5.506612, step = 30500 (37.503 sec)
I1023 20:10:48.583953 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65297
I1023 20:10:48.584738 140280393865024 basic_session_run_hooks.py:260] loss = 6.5314193, step = 30600 (37.693 sec)
I1023 20:11:26.240220 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6556
I1023 20:11:26.240885 140280393865024 basic_session_run_hooks.py:260] loss = 5.752437, step = 30700 (37.656 sec)
I1023 20:12:03.732290 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66723
I1023 20:12:03.733038 140280393865024 basic_session_run_hooks.py:260] loss = 5.922063, step = 30800 (37.492 sec)
I1023 20:12:41.551140 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64418
I1023 20:12:41.551862 140280393865024 basic_session_run_hooks.py:260] loss = 6.077436, step = 30900 (37.819 sec)
I1023 20:13:18.966467 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6727
I1023 20:13:18.967132 140280393865024 basic_session_run_hooks.py:260] loss = 5.8253646, step = 31000 (37.415 sec)
I1023 20:13:56.719333 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64881
I1023 20:13:56.720141 140280393865024 basic_session_run_hooks.py:260] loss = 6.055673, step = 31100 (37.753 sec)
I1023 20:14:34.639159 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63714
I1023 20:14:34.639826 140280393865024 basic_session_run_hooks.py:260] loss = 5.8054276, step = 31200 (37.920 sec)
I1023 20:15:12.308063 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65471
I1023 20:15:12.308821 140280393865024 basic_session_run_hooks.py:260] loss = 5.886754, step = 31300 (37.669 sec)
I1023 20:15:16.804293 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 31313 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
W1023 20:15:23.617497 140280393865024 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I1023 20:15:57.806668 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.19787
I1023 20:15:57.807378 140280393865024 basic_session_run_hooks.py:260] loss = 5.713108, step = 31400 (45.499 sec)
I1023 20:16:35.392122 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6606
I1023 20:16:35.392869 140280393865024 basic_session_run_hooks.py:260] loss = 6.08231, step = 31500 (37.585 sec)
I1023 20:17:13.110270 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65124
I1023 20:17:13.111028 140280393865024 basic_session_run_hooks.py:260] loss = 6.2232475, step = 31600 (37.718 sec)
I1023 20:17:50.724429 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65857
I1023 20:17:50.725051 140280393865024 basic_session_run_hooks.py:260] loss = 5.725674, step = 31700 (37.614 sec)
I1023 20:18:28.427537 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6523
I1023 20:18:28.428233 140280393865024 basic_session_run_hooks.py:260] loss = 5.7967668, step = 31800 (37.703 sec)
I1023 20:19:06.466385 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62889
I1023 20:19:06.467154 140280393865024 basic_session_run_hooks.py:260] loss = 5.812443, step = 31900 (38.039 sec)
I1023 20:19:43.877024 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67304
I1023 20:19:43.877723 140280393865024 basic_session_run_hooks.py:260] loss = 5.8573294, step = 32000 (37.411 sec)
I1023 20:20:21.486046 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65894
I1023 20:20:21.486889 140280393865024 basic_session_run_hooks.py:260] loss = 6.2179255, step = 32100 (37.609 sec)
I1023 20:20:59.189685 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65226
I1023 20:20:59.190480 140280393865024 basic_session_run_hooks.py:260] loss = 5.5195727, step = 32200 (37.704 sec)
I1023 20:21:36.711242 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66514
I1023 20:21:36.712097 140280393865024 basic_session_run_hooks.py:260] loss = 5.9745073, step = 32300 (37.522 sec)
I1023 20:22:14.497951 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64643
I1023 20:22:14.498650 140280393865024 basic_session_run_hooks.py:260] loss = 5.685053, step = 32400 (37.787 sec)
I1023 20:22:52.243831 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6493
I1023 20:22:52.244610 140280393865024 basic_session_run_hooks.py:260] loss = 5.973593, step = 32500 (37.746 sec)
I1023 20:23:30.000341 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64855
I1023 20:23:30.001048 140280393865024 basic_session_run_hooks.py:260] loss = 6.4116344, step = 32600 (37.756 sec)
I1023 20:24:07.853814 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64177
I1023 20:24:07.854444 140280393865024 basic_session_run_hooks.py:260] loss = 5.84057, step = 32700 (37.853 sec)
I1023 20:24:45.571517 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65127
I1023 20:24:45.572110 140280393865024 basic_session_run_hooks.py:260] loss = 5.564444, step = 32800 (37.718 sec)
I1023 20:25:17.147091 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 32885 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 20:25:37.475709 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.92663
I1023 20:25:37.476458 140280393865024 basic_session_run_hooks.py:260] loss = 5.364491, step = 32900 (51.904 sec)
I1023 20:26:15.026952 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66303
I1023 20:26:15.027694 140280393865024 basic_session_run_hooks.py:260] loss = 5.85766, step = 33000 (37.551 sec)
I1023 20:26:52.658931 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65731
I1023 20:26:52.659580 140280393865024 basic_session_run_hooks.py:260] loss = 5.6964073, step = 33100 (37.632 sec)
I1023 20:27:30.386893 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65055
I1023 20:27:30.387749 140280393865024 basic_session_run_hooks.py:260] loss = 6.4218483, step = 33200 (37.728 sec)
I1023 20:28:08.332765 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63533
I1023 20:28:08.333413 140280393865024 basic_session_run_hooks.py:260] loss = 5.754949, step = 33300 (37.946 sec)
I1023 20:28:45.919345 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66052
I1023 20:28:45.920056 140280393865024 basic_session_run_hooks.py:260] loss = 5.760877, step = 33400 (37.587 sec)
I1023 20:29:23.625875 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65206
I1023 20:29:23.626587 140280393865024 basic_session_run_hooks.py:260] loss = 5.791619, step = 33500 (37.707 sec)
I1023 20:30:01.309170 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65369
I1023 20:30:01.309942 140280393865024 basic_session_run_hooks.py:260] loss = 5.455463, step = 33600 (37.683 sec)
I1023 20:30:38.759637 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67019
I1023 20:30:38.760275 140280393865024 basic_session_run_hooks.py:260] loss = 6.003987, step = 33700 (37.450 sec)
I1023 20:31:16.817616 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62757
I1023 20:31:16.818232 140280393865024 basic_session_run_hooks.py:260] loss = 5.7559867, step = 33800 (38.058 sec)
I1023 20:31:54.381127 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66216
I1023 20:31:54.381868 140280393865024 basic_session_run_hooks.py:260] loss = 5.7905726, step = 33900 (37.564 sec)
I1023 20:32:32.063768 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65374
I1023 20:32:32.064484 140280393865024 basic_session_run_hooks.py:260] loss = 6.306105, step = 34000 (37.683 sec)
I1023 20:33:09.904884 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64263
I1023 20:33:09.905670 140280393865024 basic_session_run_hooks.py:260] loss = 5.909665, step = 34100 (37.841 sec)
I1023 20:33:47.710619 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6451
I1023 20:33:47.711498 140280393865024 basic_session_run_hooks.py:260] loss = 5.7553887, step = 34200 (37.806 sec)
I1023 20:34:25.218561 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6661
I1023 20:34:25.219390 140280393865024 basic_session_run_hooks.py:260] loss = 5.575268, step = 34300 (37.508 sec)
I1023 20:35:02.766005 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6633
I1023 20:35:02.766766 140280393865024 basic_session_run_hooks.py:260] loss = 5.8221264, step = 34400 (37.547 sec)
I1023 20:35:17.515744 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 34440 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 20:35:51.673013 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.0447
I1023 20:35:51.673672 140280393865024 basic_session_run_hooks.py:260] loss = 5.3930264, step = 34500 (48.907 sec)
I1023 20:36:29.206841 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66426
I1023 20:36:29.207558 140280393865024 basic_session_run_hooks.py:260] loss = 5.80223, step = 34600 (37.534 sec)
I1023 20:37:06.989804 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6467
I1023 20:37:06.990519 140280393865024 basic_session_run_hooks.py:260] loss = 6.091017, step = 34700 (37.783 sec)
I1023 20:37:44.410787 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6723
I1023 20:37:44.411482 140280393865024 basic_session_run_hooks.py:260] loss = 5.856369, step = 34800 (37.421 sec)
I1023 20:38:22.113679 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65232
I1023 20:38:22.114606 140280393865024 basic_session_run_hooks.py:260] loss = 6.0626063, step = 34900 (37.703 sec)
I1023 20:39:00.052026 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63586
I1023 20:39:00.052832 140280393865024 basic_session_run_hooks.py:260] loss = 5.569167, step = 35000 (37.938 sec)
I1023 20:39:37.869139 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64431
I1023 20:39:37.869792 140280393865024 basic_session_run_hooks.py:260] loss = 5.7856045, step = 35100 (37.817 sec)
I1023 20:40:15.553979 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65359
I1023 20:40:15.554778 140280393865024 basic_session_run_hooks.py:260] loss = 5.7354198, step = 35200 (37.685 sec)
I1023 20:40:53.201609 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65621
I1023 20:40:53.202355 140280393865024 basic_session_run_hooks.py:260] loss = 5.912047, step = 35300 (37.648 sec)
I1023 20:41:30.803217 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65946
I1023 20:41:30.803864 140280393865024 basic_session_run_hooks.py:260] loss = 5.665774, step = 35400 (37.602 sec)
I1023 20:42:07.790451 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.70364
I1023 20:42:07.791481 140280393865024 basic_session_run_hooks.py:260] loss = 5.875929, step = 35500 (36.988 sec)
I1023 20:42:45.117745 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.679
I1023 20:42:45.118484 140280393865024 basic_session_run_hooks.py:260] loss = 5.8531084, step = 35600 (37.327 sec)
I1023 20:43:22.647781 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66453
I1023 20:43:22.648498 140280393865024 basic_session_run_hooks.py:260] loss = 5.2799044, step = 35700 (37.530 sec)
I1023 20:44:00.140596 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66718
I1023 20:44:00.141321 140280393865024 basic_session_run_hooks.py:260] loss = 6.413248, step = 35800 (37.493 sec)
I1023 20:44:37.817061 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65418
I1023 20:44:37.817721 140280393865024 basic_session_run_hooks.py:260] loss = 5.5806584, step = 35900 (37.676 sec)
I1023 20:45:15.477187 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65533
I1023 20:45:15.477855 140280393865024 basic_session_run_hooks.py:260] loss = 5.8054104, step = 36000 (37.660 sec)
I1023 20:45:17.661676 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 36007 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 20:46:00.770493 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.20783
I1023 20:46:00.771719 140280393865024 basic_session_run_hooks.py:260] loss = 5.6991463, step = 36100 (45.294 sec)
I1023 20:46:38.434681 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65504
I1023 20:46:38.435486 140280393865024 basic_session_run_hooks.py:260] loss = 4.2435975, step = 36200 (37.664 sec)
I1023 20:47:16.230899 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64577
I1023 20:47:16.231555 140280393865024 basic_session_run_hooks.py:260] loss = 5.760234, step = 36300 (37.796 sec)
I1023 20:47:54.026879 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64578
I1023 20:47:54.027735 140280393865024 basic_session_run_hooks.py:260] loss = 5.942363, step = 36400 (37.796 sec)
I1023 20:48:31.586120 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66246
I1023 20:48:31.586803 140280393865024 basic_session_run_hooks.py:260] loss = 5.6155424, step = 36500 (37.559 sec)
I1023 20:49:09.260716 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65431
I1023 20:49:09.261539 140280393865024 basic_session_run_hooks.py:260] loss = 6.001794, step = 36600 (37.675 sec)
I1023 20:49:46.864300 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65932
I1023 20:49:46.865029 140280393865024 basic_session_run_hooks.py:260] loss = 6.029316, step = 36700 (37.603 sec)
I1023 20:50:24.419277 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66277
I1023 20:50:24.419992 140280393865024 basic_session_run_hooks.py:260] loss = 5.936582, step = 36800 (37.555 sec)
I1023 20:51:02.208634 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64624
I1023 20:51:02.209413 140280393865024 basic_session_run_hooks.py:260] loss = 5.794495, step = 36900 (37.789 sec)
I1023 20:51:40.088221 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63994
I1023 20:51:40.088960 140280393865024 basic_session_run_hooks.py:260] loss = 5.743558, step = 37000 (37.880 sec)
I1023 20:52:17.926124 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64285
I1023 20:52:17.926868 140280393865024 basic_session_run_hooks.py:260] loss = 5.8312187, step = 37100 (37.838 sec)
I1023 20:52:55.490501 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6621
I1023 20:52:55.491169 140280393865024 basic_session_run_hooks.py:260] loss = 5.772463, step = 37200 (37.564 sec)
I1023 20:53:33.066212 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66129
I1023 20:53:33.066797 140280393865024 basic_session_run_hooks.py:260] loss = 5.6386876, step = 37300 (37.576 sec)
I1023 20:54:10.806443 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64969
I1023 20:54:10.807063 140280393865024 basic_session_run_hooks.py:260] loss = 5.854987, step = 37400 (37.740 sec)
I1023 20:54:48.418251 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65874
I1023 20:54:48.419004 140280393865024 basic_session_run_hooks.py:260] loss = 5.990341, step = 37500 (37.612 sec)
I1023 20:55:17.788019 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 37579 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 20:55:39.223220 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.96831
I1023 20:55:39.224604 140280393865024 basic_session_run_hooks.py:260] loss = 5.478608, step = 37600 (50.806 sec)
I1023 20:56:16.717865 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66705
I1023 20:56:16.718710 140280393865024 basic_session_run_hooks.py:260] loss = 5.1065087, step = 37700 (37.494 sec)
I1023 20:56:54.445620 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65057
I1023 20:56:54.446515 140280393865024 basic_session_run_hooks.py:260] loss = 5.9459333, step = 37800 (37.728 sec)
I1023 20:57:32.205967 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64828
I1023 20:57:32.206752 140280393865024 basic_session_run_hooks.py:260] loss = 6.141827, step = 37900 (37.760 sec)
I1023 20:58:09.973099 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6478
I1023 20:58:09.973759 140280393865024 basic_session_run_hooks.py:260] loss = 5.917212, step = 38000 (37.767 sec)
I1023 20:58:47.635752 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65515
I1023 20:58:47.636439 140280393865024 basic_session_run_hooks.py:260] loss = 5.839743, step = 38100 (37.663 sec)
I1023 20:59:25.470341 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64308
I1023 20:59:25.471101 140280393865024 basic_session_run_hooks.py:260] loss = 5.7890387, step = 38200 (37.835 sec)
I1023 21:00:03.410244 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63575
I1023 21:00:03.411112 140280393865024 basic_session_run_hooks.py:260] loss = 5.7110505, step = 38300 (37.940 sec)
I1023 21:00:41.197384 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6464
I1023 21:00:41.198010 140280393865024 basic_session_run_hooks.py:260] loss = 6.0264077, step = 38400 (37.787 sec)
I1023 21:01:19.178078 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63292
I1023 21:01:19.178801 140280393865024 basic_session_run_hooks.py:260] loss = 5.989665, step = 38500 (37.981 sec)
I1023 21:01:56.791246 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65864
I1023 21:01:56.791984 140280393865024 basic_session_run_hooks.py:260] loss = 5.639106, step = 38600 (37.613 sec)
I1023 21:02:34.611104 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64411
I1023 21:02:34.612016 140280393865024 basic_session_run_hooks.py:260] loss = 5.555352, step = 38700 (37.820 sec)
I1023 21:03:12.650631 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62884
I1023 21:03:12.651380 140280393865024 basic_session_run_hooks.py:260] loss = 6.444669, step = 38800 (38.039 sec)
I1023 21:03:50.417886 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6478
I1023 21:03:50.418526 140280393865024 basic_session_run_hooks.py:260] loss = 5.9162054, step = 38900 (37.767 sec)
I1023 21:04:27.937630 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66526
I1023 21:04:27.938325 140280393865024 basic_session_run_hooks.py:260] loss = 4.7053204, step = 39000 (37.520 sec)
I1023 21:05:05.623333 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65353
I1023 21:05:05.624104 140280393865024 basic_session_run_hooks.py:260] loss = 6.2646, step = 39100 (37.686 sec)
I1023 21:05:18.078884 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 39134 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:05:50.300367 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.23829
I1023 21:05:50.300968 140280393865024 basic_session_run_hooks.py:260] loss = 5.887428, step = 39200 (44.677 sec)
I1023 21:06:28.010442 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65181
I1023 21:06:28.011219 140280393865024 basic_session_run_hooks.py:260] loss = 4.7894764, step = 39300 (37.710 sec)
I1023 21:07:05.575195 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66207
I1023 21:07:05.575917 140280393865024 basic_session_run_hooks.py:260] loss = 5.715632, step = 39400 (37.565 sec)
I1023 21:07:43.096669 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66514
I1023 21:07:43.097298 140280393865024 basic_session_run_hooks.py:260] loss = 5.740388, step = 39500 (37.521 sec)
I1023 21:08:20.997505 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63846
I1023 21:08:20.998154 140280393865024 basic_session_run_hooks.py:260] loss = 5.5225296, step = 39600 (37.901 sec)
I1023 21:08:58.819765 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64395
I1023 21:08:58.820780 140280393865024 basic_session_run_hooks.py:260] loss = 5.60616, step = 39700 (37.823 sec)
I1023 21:09:36.657873 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64284
I1023 21:09:36.658651 140280393865024 basic_session_run_hooks.py:260] loss = 6.5483775, step = 39800 (37.838 sec)
I1023 21:10:14.539148 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63983
I1023 21:10:14.539940 140280393865024 basic_session_run_hooks.py:260] loss = 5.597763, step = 39900 (37.881 sec)
I1023 21:10:52.229464 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6532
I1023 21:10:52.230292 140280393865024 basic_session_run_hooks.py:260] loss = 6.101717, step = 40000 (37.690 sec)
I1023 21:11:30.093424 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64103
I1023 21:11:30.094098 140280393865024 basic_session_run_hooks.py:260] loss = 6.0439277, step = 40100 (37.864 sec)
I1023 21:12:07.727068 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6572
I1023 21:12:07.727880 140280393865024 basic_session_run_hooks.py:260] loss = 5.8714037, step = 40200 (37.634 sec)
I1023 21:12:45.662642 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63605
I1023 21:12:45.663430 140280393865024 basic_session_run_hooks.py:260] loss = 5.690087, step = 40300 (37.936 sec)
I1023 21:13:23.303874 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65666
I1023 21:13:23.304659 140280393865024 basic_session_run_hooks.py:260] loss = 5.98059, step = 40400 (37.641 sec)
I1023 21:14:01.206140 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63836
I1023 21:14:01.207031 140280393865024 basic_session_run_hooks.py:260] loss = 5.584029, step = 40500 (37.902 sec)
I1023 21:14:39.270201 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62715
I1023 21:14:39.270912 140280393865024 basic_session_run_hooks.py:260] loss = 5.302096, step = 40600 (38.064 sec)
I1023 21:15:17.237645 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63384
I1023 21:15:17.238461 140280393865024 basic_session_run_hooks.py:260] loss = 6.2723513, step = 40700 (37.968 sec)
I1023 21:15:18.421154 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 40704 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:16:02.287373 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.21977
I1023 21:16:02.289257 140280393865024 basic_session_run_hooks.py:260] loss = 5.7987933, step = 40800 (45.051 sec)
I1023 21:16:39.831288 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66355
I1023 21:16:39.832107 140280393865024 basic_session_run_hooks.py:260] loss = 5.611076, step = 40900 (37.543 sec)
I1023 21:17:17.655396 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64382
I1023 21:17:17.656279 140280393865024 basic_session_run_hooks.py:260] loss = 5.976447, step = 41000 (37.824 sec)
I1023 21:17:55.677841 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63003
I1023 21:17:55.678528 140280393865024 basic_session_run_hooks.py:260] loss = 6.036167, step = 41100 (38.022 sec)
I1023 21:18:33.410095 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65025
I1023 21:18:33.410902 140280393865024 basic_session_run_hooks.py:260] loss = 5.6829033, step = 41200 (37.732 sec)
I1023 21:19:11.107721 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65269
I1023 21:19:11.108324 140280393865024 basic_session_run_hooks.py:260] loss = 6.277152, step = 41300 (37.697 sec)
I1023 21:19:48.779831 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65449
I1023 21:19:48.780951 140280393865024 basic_session_run_hooks.py:260] loss = 5.8913555, step = 41400 (37.673 sec)
I1023 21:20:26.626977 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64221
I1023 21:20:26.627703 140280393865024 basic_session_run_hooks.py:260] loss = 5.792847, step = 41500 (37.847 sec)
I1023 21:21:04.341028 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65153
I1023 21:21:04.341858 140280393865024 basic_session_run_hooks.py:260] loss = 5.4701934, step = 41600 (37.714 sec)
I1023 21:21:42.072744 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65029
I1023 21:21:42.073423 140280393865024 basic_session_run_hooks.py:260] loss = 5.6824727, step = 41700 (37.732 sec)
I1023 21:22:19.868088 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64583
I1023 21:22:19.868874 140280393865024 basic_session_run_hooks.py:260] loss = 5.86983, step = 41800 (37.795 sec)
I1023 21:22:57.984641 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62353
I1023 21:22:57.985467 140280393865024 basic_session_run_hooks.py:260] loss = 5.580388, step = 41900 (38.117 sec)
I1023 21:23:35.818395 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64314
I1023 21:23:35.819151 140280393865024 basic_session_run_hooks.py:260] loss = 6.3790092, step = 42000 (37.834 sec)
I1023 21:24:13.932676 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62369
I1023 21:24:13.933398 140280393865024 basic_session_run_hooks.py:260] loss = 5.8306804, step = 42100 (38.114 sec)
I1023 21:24:51.489046 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66266
I1023 21:24:51.489693 140280393865024 basic_session_run_hooks.py:260] loss = 5.7455583, step = 42200 (37.556 sec)
I1023 21:25:18.491124 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 42272 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:25:41.932409 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.98242
I1023 21:25:41.934283 140280393865024 basic_session_run_hooks.py:260] loss = 5.9037976, step = 42300 (50.445 sec)
I1023 21:26:19.206568 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.68282
I1023 21:26:19.207370 140280393865024 basic_session_run_hooks.py:260] loss = 5.8461895, step = 42400 (37.273 sec)
I1023 21:26:56.964015 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64848
I1023 21:26:56.964836 140280393865024 basic_session_run_hooks.py:260] loss = 5.94584, step = 42500 (37.757 sec)
I1023 21:27:34.869549 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63814
I1023 21:27:34.870319 140280393865024 basic_session_run_hooks.py:260] loss = 5.587715, step = 42600 (37.905 sec)
I1023 21:28:12.697538 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64355
I1023 21:28:12.698366 140280393865024 basic_session_run_hooks.py:260] loss = 5.7856965, step = 42700 (37.828 sec)
I1023 21:28:50.753449 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62771
I1023 21:28:50.754500 140280393865024 basic_session_run_hooks.py:260] loss = 5.9033403, step = 42800 (38.056 sec)
I1023 21:29:28.803366 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62812
I1023 21:29:28.804056 140280393865024 basic_session_run_hooks.py:260] loss = 6.036392, step = 42900 (38.050 sec)
I1023 21:30:06.490356 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65344
I1023 21:30:06.491179 140280393865024 basic_session_run_hooks.py:260] loss = 5.690645, step = 43000 (37.687 sec)
I1023 21:30:43.969400 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66816
I1023 21:30:43.970214 140280393865024 basic_session_run_hooks.py:260] loss = 5.651288, step = 43100 (37.479 sec)
I1023 21:31:21.839669 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64059
I1023 21:31:21.840359 140280393865024 basic_session_run_hooks.py:260] loss = 5.836432, step = 43200 (37.870 sec)
I1023 21:31:59.568904 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65046
I1023 21:31:59.569654 140280393865024 basic_session_run_hooks.py:260] loss = 5.2293572, step = 43300 (37.729 sec)
I1023 21:32:37.547809 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63304
I1023 21:32:37.548491 140280393865024 basic_session_run_hooks.py:260] loss = 6.3591475, step = 43400 (37.979 sec)
I1023 21:33:15.517604 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63367
I1023 21:33:15.518255 140280393865024 basic_session_run_hooks.py:260] loss = 5.6673174, step = 43500 (37.970 sec)
I1023 21:33:53.207917 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6532
I1023 21:33:53.208600 140280393865024 basic_session_run_hooks.py:260] loss = 5.7261314, step = 43600 (37.690 sec)
I1023 21:34:31.013998 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64508
I1023 21:34:31.014623 140280393865024 basic_session_run_hooks.py:260] loss = 5.4539027, step = 43700 (37.806 sec)
I1023 21:35:08.551486 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.664
I1023 21:35:08.552273 140280393865024 basic_session_run_hooks.py:260] loss = 5.9111233, step = 43800 (37.538 sec)
I1023 21:35:18.538217 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 43828 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:35:59.023597 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.98129
I1023 21:35:59.025064 140280393865024 basic_session_run_hooks.py:260] loss = 5.6429877, step = 43900 (50.473 sec)
I1023 21:36:36.504185 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66805
I1023 21:36:36.504862 140280393865024 basic_session_run_hooks.py:260] loss = 6.6774263, step = 44000 (37.480 sec)
I1023 21:37:13.827922 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67926
I1023 21:37:13.828639 140280393865024 basic_session_run_hooks.py:260] loss = 5.461365, step = 44100 (37.324 sec)
I1023 21:37:51.451318 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65792
I1023 21:37:51.452083 140280393865024 basic_session_run_hooks.py:260] loss = 5.734692, step = 44200 (37.623 sec)
I1023 21:38:29.339779 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63933
I1023 21:38:29.340444 140280393865024 basic_session_run_hooks.py:260] loss = 6.06022, step = 44300 (37.888 sec)
I1023 21:39:06.739529 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67381
I1023 21:39:06.740184 140280393865024 basic_session_run_hooks.py:260] loss = 5.4258494, step = 44400 (37.400 sec)
I1023 21:39:44.416598 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65413
I1023 21:39:44.417372 140280393865024 basic_session_run_hooks.py:260] loss = 6.1332364, step = 44500 (37.677 sec)
I1023 21:40:22.172088 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64862
I1023 21:40:22.172872 140280393865024 basic_session_run_hooks.py:260] loss = 5.9766984, step = 44600 (37.755 sec)
I1023 21:40:59.750753 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66108
I1023 21:40:59.751434 140280393865024 basic_session_run_hooks.py:260] loss = 5.85174, step = 44700 (37.579 sec)
I1023 21:41:37.708258 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63452
I1023 21:41:37.708913 140280393865024 basic_session_run_hooks.py:260] loss = 5.486633, step = 44800 (37.957 sec)
I1023 21:42:15.683782 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63328
I1023 21:42:15.684546 140280393865024 basic_session_run_hooks.py:260] loss = 5.8560133, step = 44900 (37.976 sec)
I1023 21:42:53.284855 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6595
I1023 21:42:53.285628 140280393865024 basic_session_run_hooks.py:260] loss = 5.8179555, step = 45000 (37.601 sec)
I1023 21:43:31.206097 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63704
I1023 21:43:31.206730 140280393865024 basic_session_run_hooks.py:260] loss = 5.938333, step = 45100 (37.921 sec)
I1023 21:44:09.001770 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64581
I1023 21:44:09.002423 140280393865024 basic_session_run_hooks.py:260] loss = 5.8217316, step = 45200 (37.796 sec)
I1023 21:44:46.473307 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66869
I1023 21:44:46.474006 140280393865024 basic_session_run_hooks.py:260] loss = 6.0859356, step = 45300 (37.472 sec)
I1023 21:45:18.876328 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 45387 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:45:46.796095 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.65775
I1023 21:45:46.796745 140280393865024 basic_session_run_hooks.py:260] loss = 5.9947762, step = 45400 (60.323 sec)
I1023 21:46:24.365376 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66175
I1023 21:46:24.366084 140280393865024 basic_session_run_hooks.py:260] loss = 5.7395144, step = 45500 (37.569 sec)
I1023 21:47:02.051094 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65352
I1023 21:47:02.051894 140280393865024 basic_session_run_hooks.py:260] loss = 5.6914268, step = 45600 (37.686 sec)
I1023 21:47:39.851912 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64545
I1023 21:47:39.852707 140280393865024 basic_session_run_hooks.py:260] loss = 6.147859, step = 45700 (37.801 sec)
I1023 21:48:17.611541 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64833
I1023 21:48:17.612382 140280393865024 basic_session_run_hooks.py:260] loss = 5.7974277, step = 45800 (37.760 sec)
I1023 21:48:55.341008 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65045
I1023 21:48:55.341771 140280393865024 basic_session_run_hooks.py:260] loss = 5.843934, step = 45900 (37.729 sec)
I1023 21:49:32.997462 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65559
I1023 21:49:32.998186 140280393865024 basic_session_run_hooks.py:260] loss = 5.855188, step = 46000 (37.656 sec)
I1023 21:50:10.822108 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64378
I1023 21:50:10.822740 140280393865024 basic_session_run_hooks.py:260] loss = 5.7315607, step = 46100 (37.825 sec)
I1023 21:50:48.783845 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63423
I1023 21:50:48.784532 140280393865024 basic_session_run_hooks.py:260] loss = 5.769385, step = 46200 (37.962 sec)
I1023 21:51:26.865079 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62597
I1023 21:51:26.865861 140280393865024 basic_session_run_hooks.py:260] loss = 6.4004345, step = 46300 (38.081 sec)
I1023 21:52:04.826727 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63424
I1023 21:52:04.827336 140280393865024 basic_session_run_hooks.py:260] loss = 5.7996974, step = 46400 (37.961 sec)
I1023 21:52:42.566768 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64971
I1023 21:52:42.567715 140280393865024 basic_session_run_hooks.py:260] loss = 5.7119265, step = 46500 (37.740 sec)
I1023 21:53:20.476826 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63782
I1023 21:53:20.477557 140280393865024 basic_session_run_hooks.py:260] loss = 5.940976, step = 46600 (37.910 sec)
I1023 21:53:58.610165 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.62238
I1023 21:53:58.610808 140280393865024 basic_session_run_hooks.py:260] loss = 5.9769754, step = 46700 (38.133 sec)
I1023 21:54:36.455584 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64233
I1023 21:54:36.456339 140280393865024 basic_session_run_hooks.py:260] loss = 5.7659583, step = 46800 (37.846 sec)
I1023 21:55:14.016147 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66237
I1023 21:55:14.016762 140280393865024 basic_session_run_hooks.py:260] loss = 5.4763503, step = 46900 (37.560 sec)
I1023 21:55:18.910542 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 46914 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 21:56:25.688530 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 1.39524
I1023 21:56:25.689867 140280393865024 basic_session_run_hooks.py:260] loss = 5.7641068, step = 47000 (71.673 sec)
I1023 21:57:03.565696 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64011
I1023 21:57:03.566374 140280393865024 basic_session_run_hooks.py:260] loss = 5.9015646, step = 47100 (37.877 sec)
I1023 21:57:41.182202 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65841
I1023 21:57:41.182887 140280393865024 basic_session_run_hooks.py:260] loss = 5.919203, step = 47200 (37.617 sec)
I1023 21:58:18.899804 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65128
I1023 21:58:18.900641 140280393865024 basic_session_run_hooks.py:260] loss = 5.7657285, step = 47300 (37.718 sec)
I1023 21:58:56.387145 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66757
I1023 21:58:56.388193 140280393865024 basic_session_run_hooks.py:260] loss = 5.7079473, step = 47400 (37.488 sec)
I1023 21:59:33.902791 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66556
I1023 21:59:33.903651 140280393865024 basic_session_run_hooks.py:260] loss = 5.664721, step = 47500 (37.515 sec)
I1023 22:00:11.562808 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65533
I1023 22:00:11.563478 140280393865024 basic_session_run_hooks.py:260] loss = 5.861262, step = 47600 (37.660 sec)
I1023 22:00:48.988670 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67195
I1023 22:00:48.989613 140280393865024 basic_session_run_hooks.py:260] loss = 5.764072, step = 47700 (37.426 sec)
I1023 22:01:26.859183 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64057
I1023 22:01:26.859943 140280393865024 basic_session_run_hooks.py:260] loss = 5.8119483, step = 47800 (37.870 sec)
I1023 22:02:04.601332 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64956
I1023 22:02:04.602075 140280393865024 basic_session_run_hooks.py:260] loss = 5.856939, step = 47900 (37.742 sec)
I1023 22:02:42.451899 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64197
I1023 22:02:42.452581 140280393865024 basic_session_run_hooks.py:260] loss = 6.161788, step = 48000 (37.851 sec)
I1023 22:03:20.380657 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63652
I1023 22:03:20.381389 140280393865024 basic_session_run_hooks.py:260] loss = 5.602098, step = 48100 (37.929 sec)
I1023 22:03:57.863917 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66786
I1023 22:03:57.864660 140280393865024 basic_session_run_hooks.py:260] loss = 5.776727, step = 48200 (37.483 sec)
I1023 22:04:35.378893 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6656
I1023 22:04:35.379664 140280393865024 basic_session_run_hooks.py:260] loss = 6.26263, step = 48300 (37.515 sec)
I1023 22:05:13.289935 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63775
I1023 22:05:13.290773 140280393865024 basic_session_run_hooks.py:260] loss = 5.776059, step = 48400 (37.911 sec)
I1023 22:05:18.926707 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 48416 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 22:05:57.931408 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.24007
I1023 22:05:57.932563 140280393865024 basic_session_run_hooks.py:260] loss = 5.7523127, step = 48500 (44.642 sec)
I1023 22:06:35.675032 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64945
I1023 22:06:35.675897 140280393865024 basic_session_run_hooks.py:260] loss = 5.8452044, step = 48600 (37.743 sec)
I1023 22:07:13.415507 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64967
I1023 22:07:13.416409 140280393865024 basic_session_run_hooks.py:260] loss = 6.228503, step = 48700 (37.741 sec)
I1023 22:07:51.266003 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64197
I1023 22:07:51.266743 140280393865024 basic_session_run_hooks.py:260] loss = 5.7164764, step = 48800 (37.850 sec)
I1023 22:08:28.667652 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67368
I1023 22:08:28.668381 140280393865024 basic_session_run_hooks.py:260] loss = 5.9037094, step = 48900 (37.402 sec)
I1023 22:09:06.121712 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66994
I1023 22:09:06.122302 140280393865024 basic_session_run_hooks.py:260] loss = 4.8136334, step = 49000 (37.454 sec)
I1023 22:09:43.892989 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64751
I1023 22:09:43.893686 140280393865024 basic_session_run_hooks.py:260] loss = 6.0466666, step = 49100 (37.771 sec)
I1023 22:10:21.676405 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.64666
I1023 22:10:21.677085 140280393865024 basic_session_run_hooks.py:260] loss = 5.8375206, step = 49200 (37.783 sec)
I1023 22:10:59.177915 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66656
I1023 22:10:59.178752 140280393865024 basic_session_run_hooks.py:260] loss = 5.8096757, step = 49300 (37.502 sec)
I1023 22:11:36.685916 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.6661
I1023 22:11:36.686688 140280393865024 basic_session_run_hooks.py:260] loss = 5.70187, step = 49400 (37.508 sec)
I1023 22:12:14.121508 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.67126
I1023 22:12:14.122432 140280393865024 basic_session_run_hooks.py:260] loss = 5.772127, step = 49500 (37.436 sec)
I1023 22:12:52.029588 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.63796
I1023 22:12:52.030358 140280393865024 basic_session_run_hooks.py:260] loss = 5.538337, step = 49600 (37.908 sec)
I1023 22:13:29.568751 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.66388
I1023 22:13:29.569537 140280393865024 basic_session_run_hooks.py:260] loss = 5.9571624, step = 49700 (37.539 sec)
I1023 22:14:07.249760 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65386
I1023 22:14:07.250570 140280393865024 basic_session_run_hooks.py:260] loss = 5.713208, step = 49800 (37.681 sec)
I1023 22:14:44.877535 140280393865024 basic_session_run_hooks.py:692] global_step/sec: 2.65761
I1023 22:14:44.878355 140280393865024 basic_session_run_hooks.py:260] loss = 6.025379, step = 49900 (37.628 sec)
I1023 22:15:19.269765 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 49992 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 22:15:40.293398 140280393865024 basic_session_run_hooks.py:606] Saving checkpoints for 50000 into /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt.
I1023 22:16:09.291136 140280393865024 estimator.py:368] Loss for final step: 5.6606407.





HPARAMS2!!










TRANSFORMER PREPARE ENCODER!!










TRANSFORMER PREPARE DECODER!!!






NUMBER OF PARAMTERS: 
191723520


WARNING: Logging before flag parsing goes to stderr.
W1023 22:16:15.800388 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:16: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W1023 22:16:15.800514 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:16: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W1023 22:16:15.800633 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:17: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W1023 22:16:15.800901 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:52: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W1023 22:16:15.803377 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/bleu_hook.py:243: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W1023 22:16:15.804972 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/bleu_hook.py:297: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I1023 22:16:15.805036 139804473608000 bleu_hook.py:299] Found 20 files with steps: 21904, 23473, 25033, 26598, 28172, 29744, 31313, 32885, 34440, 36007, 37579, 39134, 40704, 42272, 43828, 45387, 46914, 48416, 49992, 50000
I1023 22:16:15.810458 139804473608000 t2t_avg_all.py:71] Loading [1]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-21904
I1023 22:16:22.763596 139804473608000 t2t_avg_all.py:71] Loading [2]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-23473
I1023 22:16:28.364468 139804473608000 t2t_avg_all.py:71] Loading [3]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-25033
I1023 22:16:34.008036 139804473608000 t2t_avg_all.py:71] Loading [4]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-26598
I1023 22:16:39.527938 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-26598
W1023 22:16:39.528416 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1023 22:16:39.547249 139804473608000 deprecation.py:506] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1023 22:16:42.846175 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:85: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W1023 22:16:43.075217 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:86: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W1023 22:16:43.389477 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:92: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1023 22:16:43.391332 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:94: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W1023 22:16:43.391412 139804473608000 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

I1023 22:16:43.741372 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-26598
2019-10-23 22:16:43.742108: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-23 22:16:43.773126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:43.773475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:16:43.778090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:16:43.855854: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:16:43.899074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:16:43.910621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:16:43.983114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:16:43.993981: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:16:44.121278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:16:44.121633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.123452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.124971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:16:44.125661: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-10-23 22:16:44.159544: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-10-23 22:16:44.160665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ea9b84ad30 executing computations on platform Host. Devices:
2019-10-23 22:16:44.160741: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-23 22:16:44.161033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.161862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:16:44.161910: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:16:44.161938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:16:44.161964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:16:44.161988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:16:44.162013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:16:44.162038: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:16:44.162062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:16:44.162134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.162813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.163472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:16:44.163530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:16:44.243661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:16:44.243694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:16:44.243702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:16:44.243821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.244179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.244500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:16:44.244796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-10-23 22:16:44.244820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-10-23 22:16:44.245933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ea9efa2920 executing computations on platform CUDA. Devices:
2019-10-23 22:16:44.245946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-10-23 22:16:45.915969: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I1023 22:17:47.094944 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-26598
I1023 22:18:34.537730 139804473608000 t2t_avg_all.py:71] Loading [5]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-28172
I1023 22:18:40.327705 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-28172
I1023 22:18:44.611528 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-28172
2019-10-23 22:18:44.613040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:18:44.613332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:18:44.623849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:18:44.624759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:18:44.626489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:18:44.627228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:18:44.627259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:18:44.629926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:18:44.630734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:18:44.630797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:18:44.631090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:18:44.631383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:18:44.631412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:18:44.631421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:18:44.631429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:18:44.631484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:18:44.631758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:18:44.632016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:19:46.992272 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-28172
I1023 22:20:12.337472 139804473608000 t2t_avg_all.py:71] Loading [6]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-29744
I1023 22:20:17.717071 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-29744
I1023 22:20:22.106107 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-29744
2019-10-23 22:20:22.108230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:20:22.108523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:20:22.120069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:20:22.120952: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:20:22.122591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:20:22.123330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:20:22.123376: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:20:22.124300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:20:22.125041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:20:22.125099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:20:22.125392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:20:22.125641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:20:22.125664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:20:22.125671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:20:22.125679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:20:22.125732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:20:22.126005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:20:22.126262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:21:24.975067 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-29744
I1023 22:21:45.531814 139804473608000 t2t_avg_all.py:71] Loading [7]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-31313
I1023 22:21:50.990874 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-31313
I1023 22:21:55.530888 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-31313
2019-10-23 22:21:55.532233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:21:55.532525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:21:55.543969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:21:55.544877: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:21:55.546566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:21:55.547276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:21:55.547301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:21:55.548277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:21:55.549085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:21:55.549155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:21:55.549457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:21:55.549706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:21:55.549728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:21:55.549734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:21:55.549739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:21:55.549789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:21:55.550062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:21:55.550328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:22:58.635716 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-31313
I1023 22:23:22.260325 139804473608000 t2t_avg_all.py:71] Loading [8]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-32885
I1023 22:23:27.994573 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-32885
I1023 22:23:32.472569 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-32885
2019-10-23 22:23:32.473933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:23:32.474222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:23:32.485368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:23:32.486271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:23:32.487968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:23:32.488781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:23:32.488802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:23:32.489768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:23:32.490547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:23:32.490618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:23:32.490955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:23:32.491201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:23:32.491253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:23:32.491269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:23:32.491275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:23:32.491340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:23:32.491612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:23:32.491869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:24:35.766985 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-32885
I1023 22:25:02.079075 139804473608000 t2t_avg_all.py:71] Loading [9]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-34440
I1023 22:25:07.853527 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-34440
I1023 22:25:12.236514 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-34440
2019-10-23 22:25:12.237841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:25:12.238243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:25:12.249375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:25:12.250255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:25:12.251975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:25:12.252755: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:25:12.252780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:25:12.253739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:25:12.254519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:25:12.254589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:25:12.255010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:25:12.255425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:25:12.255453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:25:12.255462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:25:12.255470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:25:12.255538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:25:12.255933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:25:12.256306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:26:15.450804 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-34440
I1023 22:26:49.465485 139804473608000 t2t_avg_all.py:71] Loading [10]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-36007
I1023 22:26:55.046412 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-36007
I1023 22:26:59.443155 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-36007
2019-10-23 22:26:59.444501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:26:59.444792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:26:59.455298: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:26:59.456195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:26:59.457840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:26:59.458576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:26:59.458606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:26:59.459553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:26:59.460335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:26:59.460393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:26:59.460681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:26:59.460929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:26:59.460951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:26:59.460959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:26:59.460967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:26:59.461020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:26:59.461292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:26:59.461549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:28:03.254138 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-36007
I1023 22:28:17.906037 139804473608000 t2t_avg_all.py:71] Loading [11]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-37579
I1023 22:28:23.357785 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-37579
I1023 22:28:27.636465 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-37579
2019-10-23 22:28:27.637858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:28:27.638170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:28:27.648178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:28:27.649129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:28:27.650840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:28:27.651592: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:28:27.651705: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:28:27.652690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:28:27.654139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:28:27.654222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:28:27.654540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:28:27.654796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:28:27.654820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:28:27.654829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:28:27.654837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:28:27.654897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:28:27.655256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:28:27.655537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:29:31.170429 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-37579
I1023 22:29:46.613528 139804473608000 t2t_avg_all.py:71] Loading [12]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-39134
I1023 22:29:52.264007 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-39134
I1023 22:29:56.665085 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-39134
2019-10-23 22:29:56.666576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:29:56.666946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:29:56.676919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:29:56.677861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:29:56.679653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:29:56.680502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:29:56.680545: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:29:56.681495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:29:56.682270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:29:56.682380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:29:56.683307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:29:56.683948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:29:56.683996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:29:56.684011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:29:56.684028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:29:56.684157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:29:56.684840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:29:56.685452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:30:59.839439 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-39134
I1023 22:31:14.567233 139804473608000 t2t_avg_all.py:71] Loading [13]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-40704
I1023 22:31:20.108685 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-40704
I1023 22:31:24.362840 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-40704
2019-10-23 22:31:24.364240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:31:24.364544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:31:24.374745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:31:24.375763: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:31:24.377606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:31:24.378416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:31:24.378474: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:31:24.379512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:31:24.380417: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:31:24.380605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:31:24.381565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:31:24.382395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:31:24.382463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:31:24.382492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:31:24.382521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:31:24.382704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:31:24.383674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:31:24.384533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:32:27.792773 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-40704
I1023 22:32:43.928955 139804473608000 t2t_avg_all.py:71] Loading [14]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-42272
I1023 22:32:49.512664 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-42272
I1023 22:32:53.900178 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-42272
2019-10-23 22:32:53.901515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:32:53.901799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:32:53.912504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:32:53.913378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:32:53.915030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:32:53.915761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:32:53.915805: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:32:53.916763: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:32:53.917543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:32:53.917601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:32:53.917889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:32:53.918133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:32:53.918154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:32:53.918160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:32:53.918165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:32:53.918213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:32:53.918502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:32:53.918772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:33:57.353990 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-42272
I1023 22:34:19.444758 139804473608000 t2t_avg_all.py:71] Loading [15]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-43828
I1023 22:34:24.958821 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-43828
I1023 22:34:29.449554 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-43828
2019-10-23 22:34:29.450954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:34:29.451344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:34:29.461562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:34:29.462509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:34:29.464323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:34:29.465098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:34:29.465134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:34:29.466074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:34:29.466851: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:34:29.466979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:34:29.467398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:34:29.467675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:34:29.467713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:34:29.467719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:34:29.467724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:34:29.467801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:34:29.468140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:34:29.468418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:35:32.861977 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-43828
I1023 22:35:59.344208 139804473608000 t2t_avg_all.py:71] Loading [16]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-45387
I1023 22:36:05.055945 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-45387
I1023 22:36:09.508911 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-45387
2019-10-23 22:36:09.511758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:36:09.512049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:36:09.523131: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:36:09.524181: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:36:09.526000: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:36:09.526799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:36:09.526840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:36:09.527876: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:36:09.528742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:36:09.528801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:36:09.529115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:36:09.529364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:36:09.529387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:36:09.529395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:36:09.529402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:36:09.529455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:36:09.529727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:36:09.529984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:37:12.652503 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-45387
I1023 22:37:28.194639 139804473608000 t2t_avg_all.py:71] Loading [17]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-46914
I1023 22:37:33.474225 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-46914
I1023 22:37:37.865273 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-46914
2019-10-23 22:37:37.868207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:37:37.868523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:37:37.879860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:37:37.880788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:37:37.882529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:37:37.883297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:37:37.883336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:37:37.884330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:37:37.885120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:37:37.885203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:37:37.885512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:37:37.885760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:37:37.885784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:37:37.885792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:37:37.885800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:37:37.885853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:37:37.886126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:37:37.886384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:38:41.642431 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-46914
I1023 22:39:03.451927 139804473608000 t2t_avg_all.py:71] Loading [18]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-48416
I1023 22:39:08.895854 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-48416
I1023 22:39:13.260799 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-48416
2019-10-23 22:39:13.264610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:39:13.264939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:39:13.275431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:39:13.276310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:39:13.277979: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:39:13.278717: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:39:13.278745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:39:13.279840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:39:13.280590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:39:13.280685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:39:13.280995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:39:13.281296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:39:13.281332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:39:13.281338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:39:13.281343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:39:13.281432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:39:13.281723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:39:13.282003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:40:16.274733 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-48416
I1023 22:40:33.329697 139804473608000 t2t_avg_all.py:71] Loading [19]: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/model.ckpt-49992
I1023 22:40:38.785180 139804473608000 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992
I1023 22:40:43.334632 139804473608000 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992
2019-10-23 22:40:43.336139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:40:43.336451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-10-23 22:40:43.347940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-10-23 22:40:43.348825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-10-23 22:40:43.350556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-10-23 22:40:43.351295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-10-23 22:40:43.351327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-10-23 22:40:43.352264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-10-23 22:40:43.353045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-23 22:40:43.353130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:40:43.353443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:40:43.353773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-23 22:40:43.353809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-23 22:40:43.353815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-23 22:40:43.353820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-23 22:40:43.353896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:40:43.354202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-23 22:40:43.354482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9570 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I1023 22:41:46.467338 139804473608000 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992
2019-10-23 22:41:48.959045: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at save_restore_v2_ops.cc:134 : Resource exhausted: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992.data-00000-of-00001.tempstate11119917684904548641; No space left on device
Traceback (most recent call last):
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992.data-00000-of-00001.tempstate11119917684904548641; No space left on device
	 [[{{node save/SaveV2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: /home/chrisf/t2t_train/translate_ende_wmt32k/transformer_original_april2019_evolve2-conv_transformer_exp1_ctweqnumlayers1_evolve14-newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645/avg_models/newtest_exp_debug_alt_og_transcoder_convt_with_pointatten_causalpaddingonlyondecodermh_fixedMHcausal_645-last5.ckpt/model.ckpt-49992.data-00000-of-00001.tempstate11119917684904548641; No space left on device
	 [[{{node save/SaveV2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[save/SaveV2/_4632]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all", line 17, in <module>
    tf.app.run()
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all", line 12, in main
    t2t_avg_all.main(argv)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py", line 103, in main
    saver.save(sess, out_base_file, global_step=global_step)
  File "/home/chrisf/anaconda3/envs/thesis_tf/lib/pyth