nohup: ignoring input
WARNING: Logging before flag parsing goes to stderr.
W0916 18:39:51.197517 140245043787584 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0916 18:39:52.116355 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0916 18:39:53.177471 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0916 18:39:53.179961 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0916 18:39:53.180040 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:27: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0916 18:39:53.180112 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-datagen:28: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

I0916 18:39:53.180347 140245043787584 usr_dir.py:43] Importing user module Language_Model_April2019_Restart from path /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements
W0916 18:39:53.183228 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0916 18:39:53.183511 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0916 18:39:53.194319 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_datagen.py:204: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

I0916 18:39:53.194426 140245043787584 t2t_datagen.py:207] Generating problems:
    translate:
      * translate_ende_wmt8k
W0916 18:39:53.194486 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_datagen.py:156: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

I0916 18:39:53.194803 140245043787584 t2t_datagen.py:280] Generating data for translate_ende_wmt8k.
W0916 18:39:53.195082 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/translate.py:170: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

I0916 18:39:53.195756 140245043787584 translate.py:172] Skipping compile data, found files:
/home/chrisf/t2t_datagen/translate_ende_wmt8k-compiled-train.lang1
/home/chrisf/t2t_datagen/translate_ende_wmt8k-compiled-train.lang2
I0916 18:39:53.195852 140245043787584 generator_utils.py:346] Found vocab file: /home/chrisf/t2t_data/vocab.translate_ende_wmt8k.8192.subwords
W0916 18:39:53.195938 140245043787584 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

I0916 18:39:53.214447 140245043787584 generator_utils.py:153] Skipping generator because outputs files exists at ['/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00000-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00001-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00002-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00003-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00004-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00005-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00006-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00007-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00008-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00009-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00010-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00011-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00012-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00013-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00014-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00015-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00016-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00017-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00018-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00019-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00020-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00021-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00022-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00023-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00024-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00025-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00026-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00027-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00028-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00029-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00030-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00031-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00032-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00033-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00034-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00035-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00036-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00037-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00038-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00039-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00040-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00041-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00042-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00043-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00044-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00045-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00046-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00047-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00048-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00049-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00050-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00051-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00052-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00053-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00054-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00055-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00056-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00057-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00058-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00059-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00060-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00061-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00062-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00063-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00064-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00065-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00066-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00067-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00068-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00069-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00070-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00071-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00072-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00073-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00074-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00075-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00076-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00077-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00078-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00079-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00080-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00081-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00082-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00083-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00084-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00085-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00086-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00087-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00088-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00089-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00090-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00091-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00092-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00093-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00094-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00095-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00096-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00097-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00098-of-00100', '/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-train-00099-of-00100']
I0916 18:39:53.216392 140245043787584 translate.py:172] Skipping compile data, found files:
/home/chrisf/t2t_datagen/translate_ende_wmt8k-compiled-dev.lang1
/home/chrisf/t2t_datagen/translate_ende_wmt8k-compiled-dev.lang2
I0916 18:39:53.216468 140245043787584 generator_utils.py:346] Found vocab file: /home/chrisf/t2t_data/vocab.translate_ende_wmt8k.8192.subwords
I0916 18:39:53.234760 140245043787584 generator_utils.py:153] Skipping generator because outputs files exists at ['/home/chrisf/t2t_data/translate_ende_wmt8k-unshuffled-dev-00000-of-00001']
I0916 18:39:53.236392 140245043787584 generator_utils.py:527] Skipping shuffle because output files exist
WARNING: Logging before flag parsing goes to stderr.
W0916 18:39:54.270303 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0916 18:39:54.567871 139755521472320 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0916 18:39:55.944809 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0916 18:39:55.945122 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0916 18:39:55.956777 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.

W0916 18:39:55.957042 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

W0916 18:39:55.967520 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

W0916 18:39:55.988469 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0916 18:39:55.998148 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.

W0916 18:39:56.005561 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow_gan/python/contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W0916 18:39:56.005671 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow_gan/python/contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.

W0916 18:39:56.374702 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0916 18:39:56.374800 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0916 18:39:56.374946 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

I0916 18:39:56.375244 139755521472320 usr_dir.py:43] Importing user module Language_Model_April2019_Restart from path /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements
I0916 18:39:56.376666 139755521472320 t2t_trainer.py:155] Found unparsed command-line arguments. Checking if any start with --hp_ and interpreting those as hparams settings.
W0916 18:39:56.376801 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py:165: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.

W0916 18:39:56.376886 139755521472320 t2t_trainer.py:165] Found unknown flag: --allow_growth=True
W0916 18:39:56.377209 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W0916 18:39:56.377344 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W0916 18:39:56.377888 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

W0916 18:39:56.378006 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

W0916 18:39:56.378128 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:242: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
I0916 18:39:56.378242 139755521472320 trainer_lib.py:265] Configuring DataParallelism to replicate the model.
I0916 18:39:56.378297 139755521472320 devices.py:76] schedule=train
I0916 18:39:56.378333 139755521472320 devices.py:77] worker_gpu=1
I0916 18:39:56.378364 139755521472320 devices.py:78] sync=False
W0916 18:39:56.378410 139755521472320 devices.py:141] Schedule=train. Assuming that training is running on a single machine.
I0916 18:39:56.378459 139755521472320 devices.py:170] datashard_devices: ['gpu:0']
I0916 18:39:56.378535 139755521472320 devices.py:171] caching_devices: None
I0916 18:39:56.378596 139755521472320 devices.py:172] ps_devices: ['gpu:0']
W0916 18:39:56.378705 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:940: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

I0916 18:39:56.397112 139755521472320 estimator.py:209] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1afb0a21d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 60, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: OFF
  }
}
isolate_session_state: true
, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f1afb0a2250>}
W0916 18:39:56.397305 139755521472320 model_fn.py:630] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f1afb988dd0>) includes params argument, but params are not passed to Estimator.
W0916 18:39:56.405529 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0916 18:39:56.410364 139755521472320 problem.py:644] Reading data files from /home/chrisf/t2t_data/translate_ende_wmt8k-train*
I0916 18:39:56.411954 139755521472320 problem.py:670] partition: 0 num_data_files: 100
W0916 18:39:56.413277 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0916 18:39:56.450418 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
W0916 18:39:56.511694 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0916 18:39:56.538102 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/grouping.py:193: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0916 18:39:56.565426 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0916 18:39:56.571829 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
I0916 18:39:56.603865 139755521472320 estimator.py:1145] Calling model_fn.
I0916 18:39:56.611084 139755521472320 t2t_model.py:2249] Setting T2TModel mode to 'train'
W0916 18:39:56.654603 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py:244: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.

I0916 18:39:57.136284 139755521472320 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 18:39:57.389951 139755521472320 t2t_model.py:2249] Transforming feature 'inputs' with symbol_modality_8113_1024.bottom
I0916 18:39:57.470336 139755521472320 t2t_model.py:2249] Transforming feature 'targets' with symbol_modality_8113_1024.targets_bottom
I0916 18:39:57.478151 139755521472320 t2t_model.py:2249] Building model body
W0916 18:39:57.517161 139755521472320 deprecation.py:506] From /home/chrisf/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/Original_Transformer_T2TApril2019_evolve.py:2836: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0916 18:39:57.543279 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.

W0916 18:39:57.828827 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/layers/common_attention.py:1249: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

I0916 18:40:00.216680 139755521472320 t2t_model.py:2249] Transforming body output with symbol_modality_8113_1024.top
W0916 18:40:00.281812 139755521472320 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

I0916 18:40:00.282609 139755521472320 learning_rate.py:29] Base learning rate: 2.000000
I0916 18:40:00.289343 139755521472320 optimize.py:338] Trainable Variables Total size: 118496256
I0916 18:40:00.289588 139755521472320 optimize.py:338] Non-trainable variables Total size: 5
I0916 18:40:00.289732 139755521472320 optimize.py:193] Using optimizer adam
I0916 18:40:05.102650 139755521472320 estimator.py:1147] Done calling model_fn.
I0916 18:40:05.103612 139755521472320 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I0916 18:40:06.765693 139755521472320 monitored_session.py:240] Graph was finalized.
2019-09-16 18:40:06.765960: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-09-16 18:40:06.787691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-09-16 18:40:06.788465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c4cd6ad970 executing computations on platform Host. Devices:
2019-09-16 18:40:06.788482: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-16 18:40:06.789147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-16 18:40:06.814824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.815201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 18:40:06.815323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 18:40:06.816290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 18:40:06.817278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 18:40:06.817434: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 18:40:06.818392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 18:40:06.818837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 18:40:06.820820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 18:40:06.820999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.821385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.821710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 18:40:06.821749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 18:40:06.880513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 18:40:06.880539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 18:40:06.880546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 18:40:06.880656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.881007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.881328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 18:40:06.881621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-09-16 18:40:06.881643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10460 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-09-16 18:40:06.882667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c4d6bc69c0 executing computations on platform CUDA. Devices:
2019-09-16 18:40:06.882680: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-09-16 18:40:08.325257: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0916 18:40:09.334727 139755521472320 session_manager.py:500] Running local_init_op.
I0916 18:40:09.464916 139755521472320 session_manager.py:502] Done running local_init_op.
I0916 18:40:14.203551 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
2019-09-16 18:40:22.523182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 18:40:29.798279: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
I0916 18:40:31.137462 139755521472320 basic_session_run_hooks.py:262] loss = 8.290463, step = 0
I0916 18:41:04.695552 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 2.97986
I0916 18:41:04.696530 139755521472320 basic_session_run_hooks.py:260] loss = 6.968394, step = 100 (33.559 sec)
I0916 18:41:16.678558 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 146 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:41:33.199167 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.50832
I0916 18:41:33.199824 139755521472320 basic_session_run_hooks.py:260] loss = 6.4119234, step = 200 (28.503 sec)
I0916 18:41:59.766339 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.76404
I0916 18:41:59.767256 139755521472320 basic_session_run_hooks.py:260] loss = 6.258513, step = 300 (26.567 sec)
I0916 18:42:16.857373 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 366 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:42:27.916559 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.55237
I0916 18:42:27.917290 139755521472320 basic_session_run_hooks.py:260] loss = 6.218176, step = 400 (28.150 sec)
I0916 18:42:54.713483 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.73177
I0916 18:42:54.714400 139755521472320 basic_session_run_hooks.py:260] loss = 6.258747, step = 500 (26.797 sec)
I0916 18:43:17.010082 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 585 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:43:23.182296 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.51261
I0916 18:43:23.379368 139755521472320 basic_session_run_hooks.py:260] loss = 6.195701, step = 600 (28.665 sec)
I0916 18:43:49.938659 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.73743
I0916 18:43:49.939603 139755521472320 basic_session_run_hooks.py:260] loss = 6.1792994, step = 700 (26.560 sec)
I0916 18:44:16.363951 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.78426
I0916 18:44:16.364938 139755521472320 basic_session_run_hooks.py:260] loss = 6.1098843, step = 800 (26.425 sec)
I0916 18:44:17.114860 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 803 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:44:44.977017 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.49491
I0916 18:44:44.978310 139755521472320 basic_session_run_hooks.py:260] loss = 5.6903462, step = 900 (28.613 sec)
I0916 18:45:11.423009 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.78129
I0916 18:45:11.423780 139755521472320 basic_session_run_hooks.py:260] loss = 5.2217407, step = 1000 (26.445 sec)
I0916 18:45:17.261796 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 1023 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:45:40.169106 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.47874
I0916 18:45:40.170053 139755521472320 basic_session_run_hooks.py:260] loss = 5.440594, step = 1100 (28.746 sec)
I0916 18:46:06.784894 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.75717
I0916 18:46:06.785946 139755521472320 basic_session_run_hooks.py:260] loss = 5.5935125, step = 1200 (26.616 sec)
I0916 18:46:17.341509 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 1241 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:46:35.334069 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.50273
I0916 18:46:35.335112 139755521472320 basic_session_run_hooks.py:260] loss = 5.508651, step = 1300 (28.549 sec)
I0916 18:47:01.690314 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.79417
I0916 18:47:01.691156 139755521472320 basic_session_run_hooks.py:260] loss = 5.447041, step = 1400 (26.356 sec)
I0916 18:47:17.372420 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 1459 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:47:30.810782 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.43401
I0916 18:47:30.811651 139755521472320 basic_session_run_hooks.py:260] loss = 5.4911885, step = 1500 (29.120 sec)
I0916 18:47:57.217461 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.78692
I0916 18:47:57.218272 139755521472320 basic_session_run_hooks.py:260] loss = 5.481199, step = 1600 (26.407 sec)
I0916 18:48:17.411188 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 1676 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:48:26.048274 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.46851
I0916 18:48:26.049334 139755521472320 basic_session_run_hooks.py:260] loss = 5.3149457, step = 1700 (28.831 sec)
I0916 18:48:52.520856 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.77749
I0916 18:48:52.521673 139755521472320 basic_session_run_hooks.py:260] loss = 5.1029205, step = 1800 (26.472 sec)
I0916 18:49:17.616699 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 1897 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:49:20.861094 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.52855
I0916 18:49:21.418232 139755521472320 basic_session_run_hooks.py:260] loss = 5.3690286, step = 1900 (28.897 sec)
I0916 18:49:47.781064 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.71471
I0916 18:49:47.781999 139755521472320 basic_session_run_hooks.py:260] loss = 4.9340825, step = 2000 (26.364 sec)
I0916 18:50:14.245863 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.77861
I0916 18:50:14.246831 139755521472320 basic_session_run_hooks.py:260] loss = 4.913646, step = 2100 (26.465 sec)
I0916 18:50:17.663447 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 2114 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:50:42.896071 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.49038
I0916 18:50:42.897079 139755521472320 basic_session_run_hooks.py:260] loss = 5.396928, step = 2200 (28.650 sec)
I0916 18:51:09.423302 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.76971
I0916 18:51:09.424138 139755521472320 basic_session_run_hooks.py:260] loss = 5.0191503, step = 2300 (26.527 sec)
I0916 18:51:17.769070 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 2333 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:51:37.913708 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.50995
I0916 18:51:37.914568 139755521472320 basic_session_run_hooks.py:260] loss = 5.1236186, step = 2400 (28.490 sec)
I0916 18:52:04.411167 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.77395
I0916 18:52:04.412322 139755521472320 basic_session_run_hooks.py:260] loss = 5.6753087, step = 2500 (26.498 sec)
I0916 18:52:17.935656 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 2552 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:52:32.976603 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.50073
I0916 18:52:32.977514 139755521472320 basic_session_run_hooks.py:260] loss = 5.15126, step = 2600 (28.565 sec)
I0916 18:52:59.468748 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.77471
I0916 18:52:59.469578 139755521472320 basic_session_run_hooks.py:260] loss = 4.84065, step = 2700 (26.492 sec)
I0916 18:53:18.144399 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 2772 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:53:27.844448 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.52414
I0916 18:53:28.078747 139755521472320 basic_session_run_hooks.py:260] loss = 4.837675, step = 2800 (28.609 sec)
I0916 18:53:54.484982 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.75367
I0916 18:53:54.485682 139755521472320 basic_session_run_hooks.py:260] loss = 4.8465304, step = 2900 (26.407 sec)
I0916 18:54:18.151283 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 2991 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:54:22.773674 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.53498
I0916 18:54:22.781174 139755521472320 basic_session_run_hooks.py:260] loss = 4.625347, step = 3000 (28.295 sec)
I0916 18:54:49.584933 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.72978
I0916 18:54:49.585592 139755521472320 basic_session_run_hooks.py:260] loss = 4.739524, step = 3100 (26.804 sec)
I0916 18:55:15.948586 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.79311
I0916 18:55:15.949414 139755521472320 basic_session_run_hooks.py:260] loss = 4.532124, step = 3200 (26.364 sec)
I0916 18:55:18.255656 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 3210 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:55:44.305649 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.52646
I0916 18:55:44.306605 139755521472320 basic_session_run_hooks.py:260] loss = 4.7657657, step = 3300 (28.357 sec)
I0916 18:56:10.655341 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.79511
I0916 18:56:10.656279 139755521472320 basic_session_run_hooks.py:260] loss = 4.5386543, step = 3400 (26.350 sec)
I0916 18:56:18.289702 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 3430 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:56:39.043023 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.52265
I0916 18:56:39.043867 139755521472320 basic_session_run_hooks.py:260] loss = 4.361833, step = 3500 (28.388 sec)
I0916 18:57:05.258008 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.81461
I0916 18:57:05.258924 139755521472320 basic_session_run_hooks.py:260] loss = 4.765839, step = 3600 (26.215 sec)
I0916 18:57:18.445914 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 3651 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:57:33.840667 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.49863
I0916 18:57:33.841596 139755521472320 basic_session_run_hooks.py:260] loss = 4.342333, step = 3700 (28.583 sec)
I0916 18:58:00.259110 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.78523
I0916 18:58:00.260129 139755521472320 basic_session_run_hooks.py:260] loss = 4.4171267, step = 3800 (26.419 sec)
I0916 18:58:18.551060 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 3870 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:58:29.034157 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.47523
I0916 18:58:29.034854 139755521472320 basic_session_run_hooks.py:260] loss = 4.2976837, step = 3900 (28.775 sec)
I0916 18:58:55.360798 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.79844
I0916 18:58:55.361697 139755521472320 basic_session_run_hooks.py:260] loss = 4.7695885, step = 4000 (26.327 sec)
I0916 18:59:18.765466 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 4090 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 18:59:23.933831 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.4998
I0916 18:59:23.935127 139755521472320 basic_session_run_hooks.py:260] loss = 4.071934, step = 4100 (28.573 sec)
I0916 18:59:50.075331 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.82534
I0916 18:59:50.076127 139755521472320 basic_session_run_hooks.py:260] loss = 4.101325, step = 4200 (26.141 sec)
I0916 19:00:16.385895 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.80076
I0916 19:00:16.386855 139755521472320 basic_session_run_hooks.py:260] loss = 3.969635, step = 4300 (26.311 sec)
I0916 19:00:18.789201 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 4310 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
W0916 19:00:20.508946 139755521472320 deprecation.py:323] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I0916 19:00:45.160726 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.47526
I0916 19:00:45.161600 139755521472320 basic_session_run_hooks.py:260] loss = 3.848447, step = 4400 (28.775 sec)
I0916 19:01:11.464210 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.80178
I0916 19:01:11.465083 139755521472320 basic_session_run_hooks.py:260] loss = 3.642483, step = 4500 (26.303 sec)
I0916 19:01:18.857038 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 4529 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 19:01:40.038146 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.49969
I0916 19:01:40.038944 139755521472320 basic_session_run_hooks.py:260] loss = 3.8156648, step = 4600 (28.574 sec)
I0916 19:02:06.580806 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.76752
I0916 19:02:06.581725 139755521472320 basic_session_run_hooks.py:260] loss = 4.335855, step = 4700 (26.543 sec)
I0916 19:02:19.000839 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 4748 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 19:02:35.238919 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.48941
I0916 19:02:35.239713 139755521472320 basic_session_run_hooks.py:260] loss = 3.9832172, step = 4800 (28.658 sec)
I0916 19:03:01.971455 139755521472320 basic_session_run_hooks.py:692] global_step/sec: 3.74076
I0916 19:03:01.972309 139755521472320 basic_session_run_hooks.py:260] loss = 4.045407, step = 4900 (26.733 sec)
I0916 19:03:19.184475 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 4965 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 19:03:30.744421 139755521472320 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt.
I0916 19:03:37.606859 139755521472320 estimator.py:368] Loss for final step: 4.028898.





HPARAMS2!!










TRANSFORMER PREPARE ENCODER!!










TRANSFORMER PREPARE DECODER!!!






NUMBER OF PARAMTERS: 
118496256


WARNING: Logging before flag parsing goes to stderr.
W0916 19:03:42.538254 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:16: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0916 19:03:42.538409 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:16: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0916 19:03:42.538560 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/bin/t2t-avg-all:17: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0916 19:03:42.538942 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:52: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0916 19:03:42.544749 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/bleu_hook.py:243: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W0916 19:03:42.546349 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/utils/bleu_hook.py:297: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0916 19:03:42.546431 139984914745152 bleu_hook.py:299] Found 20 files with steps: 1023, 1241, 1459, 1676, 1897, 2114, 2333, 2552, 2772, 2991, 3210, 3430, 3651, 3870, 4090, 4310, 4529, 4748, 4965, 5000
I0916 19:03:42.550272 139984914745152 t2t_avg_all.py:71] Loading [1]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-1023
I0916 19:03:49.122978 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1023
W0916 19:03:49.123118 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0916 19:03:49.130237 139984914745152 deprecation.py:506] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0916 19:03:50.743811 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:85: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0916 19:03:50.854177 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:86: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W0916 19:03:51.011810 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:92: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0916 19:03:51.013673 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:94: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0916 19:03:51.013767 139984914745152 deprecation_wrapper.py:119] From /home/chrisf/anaconda3/envs/thesis_tf/lib/python3.7/site-packages/tensor2tensor/bin/t2t_avg_all.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

I0916 19:03:51.189892 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1023
2019-09-16 19:03:51.190666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-16 19:03:51.218598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.219154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:03:51.220167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:03:51.224764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:03:51.227135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:03:51.229787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:03:51.233518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:03:51.234749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:03:51.246384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:03:51.246595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.247799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.249032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:03:51.249438: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-09-16 19:03:51.279684: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-09-16 19:03:51.280427: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56163e9a2740 executing computations on platform Host. Devices:
2019-09-16 19:03:51.280460: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-16 19:03:51.280631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.281464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:03:51.281511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:03:51.281540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:03:51.281556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:03:51.281569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:03:51.281582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:03:51.281598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:03:51.281612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:03:51.281675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.282255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.282775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:03:51.282809: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:03:51.354056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:03:51.354085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:03:51.354096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:03:51.354219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.354555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.354866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:03:51.355202: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-09-16 19:03:51.355226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-09-16 19:03:51.356413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56164098eb60 executing computations on platform CUDA. Devices:
2019-09-16 19:03:51.356426: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-09-16 19:03:52.116030: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0916 19:04:08.282497 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1023
I0916 19:04:11.384472 139984914745152 t2t_avg_all.py:71] Loading [2]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-1241
I0916 19:04:19.558542 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1241
I0916 19:04:21.699090 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1241
2019-09-16 19:04:21.699505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:21.699827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:04:21.699870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:04:21.699885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:04:21.699907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:04:21.699929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:04:21.699938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:04:21.699946: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:04:21.699955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:04:21.700018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:21.700293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:21.700547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:04:21.700566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:04:21.700572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:04:21.700576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:04:21.700650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:21.700991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:21.701291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:04:37.923006 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1241
I0916 19:04:40.784449 139984914745152 t2t_avg_all.py:71] Loading [3]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-1459
I0916 19:04:45.374331 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1459
I0916 19:04:47.470385 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1459
2019-09-16 19:04:47.470847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:47.471172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:04:47.471215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:04:47.471225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:04:47.471234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:04:47.471242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:04:47.471251: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:04:47.471259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:04:47.471268: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:04:47.471301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:47.471621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:47.471907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:04:47.471926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:04:47.471932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:04:47.471937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:04:47.471982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:47.472273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:04:47.472559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:05:03.302614 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1459
I0916 19:05:14.386816 139984914745152 t2t_avg_all.py:71] Loading [4]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-1676
I0916 19:05:21.572267 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1676
I0916 19:05:23.650338 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1676
2019-09-16 19:05:23.650749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:23.651061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:05:23.651098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:05:23.651110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:05:23.651120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:05:23.651127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:05:23.651135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:05:23.651143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:05:23.651151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:05:23.651188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:23.651498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:23.651829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:05:23.651856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:05:23.651862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:05:23.651867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:05:23.651918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:23.652210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:23.652482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:05:40.846674 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1676
I0916 19:05:43.756328 139984914745152 t2t_avg_all.py:71] Loading [5]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-1897
I0916 19:05:49.649380 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1897
I0916 19:05:51.831306 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1897
2019-09-16 19:05:51.831637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:51.831943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:05:51.831970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:05:51.831979: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:05:51.831988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:05:51.831996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:05:51.832006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:05:51.832014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:05:51.832022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:05:51.832060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:51.832345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:51.832607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:05:51.832627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:05:51.832632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:05:51.832637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:05:51.832683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:51.833504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:05:51.833852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:06:08.326455 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-1897
I0916 19:06:11.163720 139984914745152 t2t_avg_all.py:71] Loading [6]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-2114
I0916 19:06:19.948468 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2114
I0916 19:06:22.096810 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2114
2019-09-16 19:06:22.097209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:22.097530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:06:22.097576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:06:22.097586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:06:22.097607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:06:22.097615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:06:22.097637: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:06:22.097646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:06:22.097655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:06:22.097716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:22.098029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:22.098367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:06:22.098402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:06:22.098408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:06:22.098413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:06:22.098459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:22.098734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:22.099035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:06:38.882625 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2114
I0916 19:06:51.144685 139984914745152 t2t_avg_all.py:71] Loading [7]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-2333
I0916 19:06:57.064798 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2333
I0916 19:06:59.220479 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2333
2019-09-16 19:06:59.220954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:59.221280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:06:59.221329: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:06:59.221352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:06:59.221375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:06:59.221383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:06:59.221391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:06:59.221400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:06:59.221409: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:06:59.221473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:59.221787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:59.222146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:06:59.222188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:06:59.222194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:06:59.222199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:06:59.222276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:59.222593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:06:59.222865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:07:16.373956 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2333
I0916 19:07:26.527452 139984914745152 t2t_avg_all.py:71] Loading [8]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-2552
I0916 19:07:32.415616 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2552
I0916 19:07:34.513269 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2552
2019-09-16 19:07:34.559232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:07:34.559656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:07:34.580163: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:07:34.581040: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:07:34.582726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:07:34.583435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:07:34.583458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:07:34.584827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:07:34.585555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:07:34.585633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:07:34.585984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:07:34.586287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:07:34.586324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:07:34.586331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:07:34.586337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:07:34.586395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:07:34.586716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:07:34.587022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:07:51.243131 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2552
I0916 19:07:54.166147 139984914745152 t2t_avg_all.py:71] Loading [9]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-2772
I0916 19:08:07.676964 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2772
I0916 19:08:09.808429 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2772
2019-09-16 19:08:09.808783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:09.809092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:08:09.809120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:08:09.809129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:08:09.809137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:08:09.809145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:08:09.809154: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:08:09.809162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:08:09.809170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:08:09.809202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:09.809504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:09.809774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:08:09.809793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:08:09.809798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:08:09.809802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:08:09.809847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:09.810140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:09.810417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:08:26.674875 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2772
I0916 19:08:30.635061 139984914745152 t2t_avg_all.py:71] Loading [10]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-2991
I0916 19:08:36.988080 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2991
I0916 19:08:39.285490 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2991
2019-09-16 19:08:39.285821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:39.286128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:08:39.286156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:08:39.286165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:08:39.286173: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:08:39.286182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:08:39.286190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:08:39.286203: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:08:39.286212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:08:39.286246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:39.286535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:39.286800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:08:39.286820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:08:39.286825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:08:39.286829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:08:39.286876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:39.287164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:08:39.287443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:08:56.220150 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-2991
I0916 19:08:59.380403 139984914745152 t2t_avg_all.py:71] Loading [11]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-3210
I0916 19:09:03.845962 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3210
I0916 19:09:05.907659 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3210
2019-09-16 19:09:05.908113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:05.908455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:09:05.908498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:09:05.908508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:09:05.908533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:09:05.908557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:09:05.908565: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:09:05.908573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:09:05.908581: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:09:05.908643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:05.908991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:05.909310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:09:05.909344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:09:05.909350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:09:05.909355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:09:05.909401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:05.909711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:05.910024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:09:22.191903 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3210
I0916 19:09:25.115038 139984914745152 t2t_avg_all.py:71] Loading [12]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-3430
I0916 19:09:29.896797 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3430
I0916 19:09:32.044284 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3430
2019-09-16 19:09:32.044659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:32.044988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:09:32.045031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:09:32.045041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:09:32.045062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:09:32.045084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:09:32.045092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:09:32.045100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:09:32.045110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:09:32.045175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:32.045479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:32.045824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:09:32.045857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:09:32.045864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:09:32.045868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:09:32.045926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:32.046224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:09:32.046497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:09:48.148540 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3430
I0916 19:09:55.255394 139984914745152 t2t_avg_all.py:71] Loading [13]: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/model.ckpt-3651
I0916 19:10:00.808614 139984914745152 t2t_avg_all.py:81] Averaging /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3651
I0916 19:10:03.058132 139984914745152 t2t_avg_all.py:96] Running session for /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3651
2019-09-16 19:10:03.061266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:10:03.061773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2019-09-16 19:10:03.076653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-16 19:10:03.077558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-16 19:10:03.079403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-16 19:10:03.080186: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-16 19:10:03.080210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-16 19:10:03.081699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-16 19:10:03.082454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 19:10:03.082519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:10:03.082872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:10:03.083191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 19:10:03.083218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 19:10:03.083227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 19:10:03.083235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 19:10:03.083289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:10:03.083659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 19:10:03.083956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9676 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
I0916 19:10:19.584764 139984914745152 t2t_avg_all.py:102] Storing to /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390/avg_models/newtest_exp_debug_decoding_general_newConvt_8k_small_hparamsearch_1024batch_390-last5.ckpt/model.ckpt-3651
2019-09-16 19:10:20.141343: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at save_restore_v2_ops.cc:134 : Resource exhausted: /home/chrisf/t2t_train/translate_ende_wmt8k/transformer_original_april2019_evolve-conv_transformer_exp1_ctweqnumlayers1_evolve2-newtest_exp_debug_decoding_general_newConv