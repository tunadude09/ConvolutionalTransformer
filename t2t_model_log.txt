nohup: ignoring input
INFO:tensorflow:Importing user module Language_Model_April2019_Restart from path /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements
INFO:tensorflow:Generating problems:
    translate:
      * translate_ende_wmt32k
INFO:tensorflow:Generating data for translate_ende_wmt32k.
INFO:tensorflow:Skipping compile data, found files:
/home/tuna/t2t_datagen/translate_ende_wmt32k-compiled-train.lang1
/home/tuna/t2t_datagen/translate_ende_wmt32k-compiled-train.lang2
INFO:tensorflow:Found vocab file: /home/tuna/t2t_data/vocab.translate_ende_wmt32k.32768.subwords
INFO:tensorflow:Skipping generator because outputs files exists at ['/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00000-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00001-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00002-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00003-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00004-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00005-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00006-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00007-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00008-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00009-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00010-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00011-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00012-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00013-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00014-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00015-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00016-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00017-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00018-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00019-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00020-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00021-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00022-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00023-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00024-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00025-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00026-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00027-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00028-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00029-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00030-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00031-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00032-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00033-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00034-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00035-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00036-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00037-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00038-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00039-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00040-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00041-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00042-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00043-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00044-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00045-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00046-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00047-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00048-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00049-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00050-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00051-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00052-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00053-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00054-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00055-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00056-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00057-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00058-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00059-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00060-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00061-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00062-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00063-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00064-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00065-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00066-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00067-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00068-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00069-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00070-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00071-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00072-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00073-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00074-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00075-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00076-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00077-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00078-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00079-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00080-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00081-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00082-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00083-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00084-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00085-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00086-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00087-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00088-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00089-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00090-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00091-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00092-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00093-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00094-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00095-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00096-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00097-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00098-of-00100', '/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-train-00099-of-00100']
INFO:tensorflow:Skipping compile data, found files:
/home/tuna/t2t_datagen/translate_ende_wmt32k-compiled-dev.lang1
/home/tuna/t2t_datagen/translate_ende_wmt32k-compiled-dev.lang2
INFO:tensorflow:Found vocab file: /home/tuna/t2t_data/vocab.translate_ende_wmt32k.32768.subwords
INFO:tensorflow:Skipping generator because outputs files exists at ['/home/tuna/t2t_data/translate_ende_wmt32k-unshuffled-dev-00000-of-00001']
INFO:tensorflow:Skipping shuffle because output files exist

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Importing user module Language_Model_April2019_Restart from path /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements
INFO:tensorflow:Found unparsed command-line arguments. Checking if any start with --hp_ and interpreting those as hparams settings.
WARNING:tensorflow:Found unknown flag: --allow_growth=True
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
INFO:tensorflow:Configuring DataParallelism to replicate the model.
INFO:tensorflow:schedule=continuous_train_and_eval
INFO:tensorflow:worker_gpu=1
INFO:tensorflow:sync=False
WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.
INFO:tensorflow:datashard_devices: ['gpu:0']
INFO:tensorflow:caching_devices: None
INFO:tensorflow:ps_devices: ['gpu:0']
INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8160dd7710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: OFF
  }
}
isolate_session_state: true
, '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/tuna/t2t_train/translate_ende_wmt32k/conv_transformer_april2019-conv_transformer_exp1_ctweqnumlayers1-exp1_ctweqnumlayers_14', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f815f8aa198>}
WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f8160328ae8>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate
INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
INFO:tensorflow:Reading data files from /home/tuna/t2t_data/translate_ende_wmt32k-train*
INFO:tensorflow:partition: 0 num_data_files: 100
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Setting T2TModel mode to 'train'
INFO:tensorflow:Using variable initializer: uniform_unit_scaling
INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_33288_64.bottom
WARNING:tensorflow:From /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
INFO:tensorflow:Transforming feature 'targets' with symbol_modality_33288_64.targets_bottom
INFO:tensorflow:Building model body
WARNING:tensorflow:From /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py:2274: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py:792: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
WARNING:tensorflow:From /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py:743: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv2d instead.
INFO:tensorflow:Transforming body output with symbol_modality_33288_64.top
INFO:tensorflow:Base learning rate: 2.000000
INFO:tensorflow:Trainable Variables Total size: 2462112
INFO:tensorflow:Non-trainable variables Total size: 5
INFO:tensorflow:Using optimizer adam
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
2019-06-01 14:20:16.513018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-06-01 14:20:16.517434: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2903930000 Hz
2019-06-01 14:20:16.518247: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5559c74b4cb0 executing computations on platform Host. Devices:
2019-06-01 14:20:16.518265: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-01 14:20:16.560174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-01 14:20:16.561185: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5559c87291d0 executing computations on platform CUDA. Devices:
2019-06-01 14:20:16.561212: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M2000M, Compute Capability 5.0
2019-06-01 14:20:16.561543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Quadro M2000M major: 5 minor: 0 memoryClockRate(GHz): 1.137
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.40GiB
2019-06-01 14:20:16.561566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-01 14:20:16.562973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-01 14:20:16.562990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-06-01 14:20:16.562998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-06-01 14:20:16.563215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3841 MB memory) -> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-06-01 14:20:16.940877: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 3.75G (4028170240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /home/tuna/t2t_train/translate_ende_wmt32k/conv_transformer_april2019-conv_transformer_exp1_ctweqnumlayers1-exp1_ctweqnumlayers_14/model.ckpt.
2019-06-01 14:20:22.567961: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2019-06-01 14:20:22.573585: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.576765: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.579813: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.583665: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.589990: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.596282: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.602290: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.606045: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.608883: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.613516: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.616896: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.620512: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.623840: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.628801: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.631803: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.635489: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.638812: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.643608: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.646477: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.649414: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:22.652860: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-01 14:20:27.304795: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-01 14:20:27.332257: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-01 14:20:27.370075: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-01 14:20:27.376647: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.


NUMBER OF PARAMTERS: 
2462112


Traceback (most recent call last):
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1334, in _do_call
    return fn(*args)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/decoder/layer_0/self_attention/multihead_attention/conv1d/conv1d/Conv2D}}]]
	 [[{{node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/encoder/layer_0/self_attention/multihead_attention/pointwise_attention/Max}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-trainer", line 33, in <module>
    tf.app.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-trainer", line 28, in main
    t2t_trainer.main(argv)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 401, in main
    execute_schedule(exp)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 356, in execute_schedule
    getattr(exp, FLAGS.schedule)()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py", line 401, in continuous_train_and_eval
    self._eval_spec)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 471, in train_and_evaluate
    return executor.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 611, in run
    return self.run_local()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 712, in run_local
    saving_listeners=saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1158, in _train_model_default
    saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1407, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 676, in run
    run_metadata=run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 1171, in run
    run_metadata=run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 1270, in run
    raise six.reraise(*original_exc_info)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/six.py", line 693, in reraise
    raise value
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 1255, in run
    return self._sess.run(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 1327, in run
    run_metadata=run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 1091, in run
    return self._sess.run(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 929, in run
    run_metadata_ptr)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1328, in _do_run
    run_metadata)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/decoder/layer_0/self_attention/multihead_attention/conv1d/conv1d/Conv2D (defined at /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py:775) ]]
	 [[node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/encoder/layer_0/self_attention/multihead_attention/pointwise_attention/Max (defined at /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/layers/common_attention.py:1199) ]]

Caused by op 'conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/decoder/layer_0/self_attention/multihead_attention/conv1d/conv1d/Conv2D', defined at:
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-trainer", line 33, in <module>
    tf.app.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-trainer", line 28, in main
    t2t_trainer.main(argv)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 401, in main
    execute_schedule(exp)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 356, in execute_schedule
    getattr(exp, FLAGS.schedule)()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py", line 401, in continuous_train_and_eval
    self._eval_spec)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 471, in train_and_evaluate
    return executor.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 611, in run
    return self.run_local()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 712, in run_local
    saving_listeners=saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1112, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py", line 1414, in wrapping_model_fn
    use_tpu=use_tpu)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py", line 1477, in estimator_model_fn
    logits, losses_dict = model(features)  # pylint: disable=not-callable
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/layers/base.py", line 530, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 554, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py", line 323, in call
    sharded_logits, losses = self.model_fn_sharded(sharded_features)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py", line 400, in model_fn_sharded
    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py", line 231, in __call__
    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/t2t_model.py", line 427, in model_fn
    body_out = self.body(transformed_features)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 2505, in body
    **decode_kwargs
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 2415, in decode
    **kwargs)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 2350, in transformer_decode
    **kwargs)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 3901, in transformer_decoder
    depthwise_sep=hparams.depthwise_sep[layer])
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 1523, in multihead_attention
    layer_collection=layer_collection)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 1148, in compute_qkv
    layer_collection=layer_collection)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 1082, in compute_attention_component
    depthwise_sep=depthwise_sep)
  File "/home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py", line 775, in depthwise_sep_dilated_causal_conv1d
    strides=strides, padding="VALID", dilation_rate=dilation_rate)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 324, in new_func
    return func(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py", line 218, in conv1d
    return layer.apply(inputs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1227, in apply
    return self.__call__(inputs, *args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/layers/base.py", line 530, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 554, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py", line 384, in call
    return super(Conv1D, self).call(inputs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py", line 194, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 966, in __call__
    return self.conv_op(inp, filter)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 591, in __call__
    return self.call(inp, filter)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 208, in __call__
    name=self.name)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 197, in _conv1d
    name=name)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 3482, in conv1d
    data_format=data_format)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 1026, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 3300, in create_op
    op_def=op_def)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/decoder/layer_0/self_attention/multihead_attention/conv1d/conv1d/Conv2D (defined at /home/tuna/t2t_user_dir/DEFENSE_langage_model_experiements/Language_Model_April2019_Restart/ConvTransformer_T2TApril2019_2.py:775) ]]
	 [[node conv_transformer_april2019/parallel_0_5/conv_transformer_april2019/conv_transformer_april2019/body/encoder/layer_0/self_attention/multihead_attention/pointwise_attention/Max (defined at /home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/layers/common_attention.py:1199) ]]

python: can't open file 'avg_checkpoints.py': [Errno 2] No such file or directory

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Traceback (most recent call last):
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-decoder", line 17, in <module>
    tf.app.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-decoder", line 12, in main
    t2t_decoder.main(argv)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_decoder.py", line 186, in main
    hp = create_hparams()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_decoder.py", line 68, in create_hparams
    problem_name=FLAGS.problem)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/hparams_lib.py", line 48, in create_hparams
    hparams = registry.hparams(hparams_set)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/registry.py", line 254, in __getitem__
    (key, self.name, display_list_by_prefix(sorted(self), 4)))
KeyError: 'conv_transformer_exp1_ctweqnumlayers1 never registered with registry hparams. Available:\n     adaptive:\n      * adaptive_universal_transformer_base\n      * adaptive_universal_transformer_base_dropout03\n      * adaptive_universal_transformer_base_dropout05\n      * adaptive_universal_transformer_base_tpu\n      * adaptive_universal_transformer_concat_tiny\n      * adaptive_universal_transformer_global_base\n      * adaptive_universal_transformer_global_base_tpu\n      * adaptive_universal_transformer_mix_after_ut_base\n      * adaptive_universal_transformer_mix_before_ut_base\n      * adaptive_universal_transformer_multilayer_hard\n      * adaptive_universal_transformer_multilayer_tpu\n      * adaptive_universal_transformer_position_random_timing_tiny\n      * adaptive_universal_transformer_small\n      * adaptive_universal_transformer_tall\n      * adaptive_universal_transformer_tall_actlossw0\n      * adaptive_universal_transformer_tall_actlossw001\n      * adaptive_universal_transformer_tiny\n      * adaptive_universal_transformer_with_sru_base\n    afx:\n      * afx_adafactor\n      * afx_adam\n      * afx_base\n      * afx_clip\n      * afx_clip2\n      * afx_clip_factored\n      * afx_factored\n      * afx_fast\n      * afx_mimic_adam\n      * afx_pow05\n      * afx_pow08\n      * afx_pow08_clip\n      * afx_pow10\n      * afx_relative\n      * afx_small\n      * afx_small_bfloat16\n      * afx_small_p10\n      * afx_small_p11\n      * afx_small_p12\n      * afx_small_p16\n      * afx_small_p8\n      * afx_unscale\n      * afx_unscale_relative\n    aligned:\n      * aligned_8k\n      * aligned_8k_grouped\n      * aligned_base\n      * aligned_grouped\n      * aligned_local\n      * aligned_local_1k\n      * aligned_local_expert\n      * aligned_lsh\n      * aligned_memory_efficient\n      * aligned_moe\n      * aligned_no_att\n      * aligned_no_timing\n      * aligned_pos_emb\n      * aligned_pseudolocal\n      * aligned_pseudolocal_256\n    attention:\n      * attention_lm_11k\n      * attention_lm_12k\n      * attention_lm_16k\n      * attention_lm_ae_extended\n      * attention_lm_attention_moe_tiny\n      * attention_lm_base\n      * attention_lm_hybrid_v2\n      * attention_lm_moe_24b_diet\n      * attention_lm_moe_32b_diet\n      * attention_lm_moe_base\n      * attention_lm_moe_base_ae\n      * attention_lm_moe_base_hybrid\n      * attention_lm_moe_base_local\n      * attention_lm_moe_base_long_seq\n      * attention_lm_moe_base_memeff\n      * attention_lm_moe_large\n      * attention_lm_moe_large_diet\n      * attention_lm_moe_memory_efficient\n      * attention_lm_moe_small\n      * attention_lm_moe_tiny\n      * attention_lm_moe_translation\n      * attention_lm_moe_unscramble_base\n      * attention_lm_no_moe_small\n      * attention_lm_small\n      * attention_lm_translation\n      * attention_lm_translation_full_attention\n      * attention_lm_translation_l12\n    autoencoder:\n      * autoencoder_autoregressive\n      * autoencoder_basic\n      * autoencoder_basic_discrete\n      * autoencoder_discrete_cifar\n      * autoencoder_discrete_pong\n      * autoencoder_discrete_tiny\n      * autoencoder_ordered_discrete\n      * autoencoder_ordered_discrete_hs256\n      * autoencoder_ordered_discrete_image64\n      * autoencoder_ordered_discrete_patched\n      * autoencoder_ordered_discrete_single\n      * autoencoder_ordered_discrete_vq\n      * autoencoder_ordered_text\n      * autoencoder_ordered_text_small\n      * autoencoder_residual\n      * autoencoder_residual_discrete\n      * autoencoder_residual_discrete_big\n      * autoencoder_residual_text\n      * autoencoder_stacked\n    basic:\n      * basic_1\n      * basic_fc_small\n      * basic_policy_parameters\n    bytenet:\n      * bytenet_base\n    cycle:\n      * cycle_gan_small\n    denoise:\n      * denoise_dense_2_m30\n      * denoise_m15\n      * denoise_m30\n      * denoise_t15\n      * denoise_v1_m15\n      * denoise_v1_m30\n      * denoise_v1_m50\n      * denoise_v1_t15\n      * denoise_v1_z15\n      * denoise_z15\n    discrete:\n      * discrete_random_action_base\n    distill:\n      * distill_resnet_32_to_15_cifar20x5\n    dqn:\n      * dqn_atari_base\n      * dqn_original_params\n    evolved:\n      * evolved_transformer_base\n      * evolved_transformer_base_tpu\n      * evolved_transformer_big\n      * evolved_transformer_big_tpu\n    frame:\n      * frame_glow_hparams\n    gene:\n      * gene_expression_conv_base\n    glow:\n      * glow_hparams\n    image:\n      * image_transformer2d_base\n      * image_transformer_base\n    imagetransformer1d:\n      * imagetransformer1d_base_12l_64by64\n      * imagetransformer1d_base_8l_64by64\n    imagetransformer2d:\n      * imagetransformer2d_base\n      * imagetransformer2d_base_12l_8_16_big\n      * imagetransformer2d_base_12l_8_64_64by64\n      * imagetransformer2d_base_14l_8_16_big\n      * imagetransformer2d_base_14l_8_16_big_uncond\n      * imagetransformer2d_base_8l_8_16\n      * imagetransformer2d_base_8l_8_16_big\n      * imagetransformer2d_base_8l_8_16_big_16k\n      * imagetransformer2d_base_8l_8_16_ls\n      * imagetransformer2d_base_8l_8_32_big\n      * imagetransformer2d_base_8l_8_64_64by64\n      * imagetransformer2d_tiny\n    imagetransformer:\n      * imagetransformer_ae_cifar\n      * imagetransformer_b10l_4h_big_uncond_dr01_tpu\n      * imagetransformer_b10l_4h_big_uncond_dr03_lr025_tpu\n      * imagetransformer_b10l_4h_big_uncond_dr03_tpu\n      * imagetransformer_b10l_dr03_moe_tpu\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr01_im\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr03_tpu\n      * imagetransformer_b12l_4h_b128_uncond_dr03_tpu\n      * imagetransformer_b12l_4h_b256_uncond_dr03_rel_tpu\n      * imagetransformer_b12l_4h_b256_uncond_dr03_tpu\n      * imagetransformer_b12l_4h_big_uncond_dr03_lr025_tpu\n      * imagetransformer_b12l_4h_big_uncond_dr03_tpu\n      * imagetransformer_b12l_4h_uncond_dr03_tpu\n      * imagetransformer_b12l_8h_b256_uncond_dr03_tpu\n      * imagetransformer_bas8l_8h_big_uncond_dr03_imgnet\n      * imagetransformer_base\n      * imagetransformer_base_10l_16h_big_dr01_imgnet\n      * imagetransformer_base_10l_16h_big_dr01_moe_imgnet\n      * imagetransformer_base_10l_16h_big_uncond_dr01_imgnet\n      * imagetransformer_base_10l_8h_big_cond_dr03_dan\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64_2d\n      * imagetransformer_base_12l_8h_big\n      * imagetransformer_base_12l_8h_big_uncond\n      * imagetransformer_base_14l_8h_big\n      * imagetransformer_base_14l_8h_big_dr01\n      * imagetransformer_base_14l_8h_big_uncond\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_128\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_b\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_c\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_d\n      * imagetransformer_base_imagenet_tpu\n      * imagetransformer_base_rel\n      * imagetransformer_base_tpu\n      * imagetransformer_cifar10_base\n      * imagetransformer_cifar10_base_dmol\n      * imagetransformer_imagenet32_base\n      * imagetransformer_moe_tiny\n      * imagetransformer_sep_channels\n      * imagetransformer_sep_channels_12l_16h_imagenet_large\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc_128\n      * imagetransformer_sep_channels_8l\n      * imagetransformer_sep_channels_8l_8h\n      * imagetransformer_sep_channels_8l_8h_local_and_global_att\n      * imagetransformer_sep_channels_8l_multipos3\n      * imagetransformer_sep_channels_8l_tpu\n      * imagetransformer_sep_output_channels_8l_local_and_global_att\n      * imagetransformer_tiny\n      * imagetransformer_tiny_tpu\n    imagetransformerpp:\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_a\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_b\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_g\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_k\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_l\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_bs1\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_rel\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_relsh\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_eval\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p_bs1\n      * imagetransformerpp_base_5l_8h_big_uncond_dr00_dan_g_bs1\n      * imagetransformerpp_base_5l_8h_dr00_dan_g_bs1_adafactor\n      * imagetransformerpp_base_6l_8h_dr00_dan_g_bs1_adafactor\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan_a\n      * imagetransformerpp_sep_channels_8l_8h\n      * imagetransformerpp_tiny\n    img2img:\n      * img2img_transformer2d_base\n      * img2img_transformer2d_n103\n      * img2img_transformer2d_n24\n      * img2img_transformer2d_n3\n      * img2img_transformer2d_n31\n      * img2img_transformer2d_n44\n      * img2img_transformer2d_q1\n      * img2img_transformer2d_q2\n      * img2img_transformer2d_q3\n      * img2img_transformer2d_tiny\n      * img2img_transformer_b1\n      * img2img_transformer_b2\n      * img2img_transformer_b3\n      * img2img_transformer_b3_bs1\n      * img2img_transformer_b3_bs10\n      * img2img_transformer_b3_bs2\n      * img2img_transformer_b3_bs3\n      * img2img_transformer_b3_bs4\n      * img2img_transformer_b3_bs5\n      * img2img_transformer_b3_bs6\n      * img2img_transformer_b3_bs7\n      * img2img_transformer_b3_bs8\n      * img2img_transformer_b3_bs9\n      * img2img_transformer_base\n      * img2img_transformer_base_tpu\n      * img2img_transformer_dilated\n      * img2img_transformer_tiny\n      * img2img_transformer_tiny_tpu\n    lmx:\n      * lmx_base\n      * lmx_h1k_f4k\n      * lmx_h1k_f64k\n      * lmx_h2k_f8k\n      * lmx_h3k_f12k\n      * lmx_h4k_f16k\n      * lmx_moe\n      * lmx_moe_h1k_f4k_x32\n      * lmx_moe_h1k_f8k_x16\n      * lmx_relative\n      * lmx_relative_nopos\n    lstm:\n      * lstm_area_attention_base\n      * lstm_area_attention_char\n      * lstm_area_attention_char_enfr\n      * lstm_area_attention_enfr\n      * lstm_asr_v1\n      * lstm_attention\n      * lstm_bahdanau_attention\n      * lstm_bahdanau_attention_multi\n      * lstm_luong_attention\n      * lstm_luong_attention_multi\n      * lstm_seq2seq\n    mqp:\n      * mqp_ende_base\n      * mqp_ende_h1_ff6784\n      * mqp_ende_h1_kv1024\n      * mqp_ende_h2_ff6400\n      * mqp_ende_h2_kv512\n      * mqp_ende_h2_kv64_ff6784\n      * mqp_ende_h4_ff5632\n      * mqp_ende_h4_kv256\n      * mqp_ende_h4_kv32_ff6784\n      * mqp_ende_h8_kv16_ff6784\n      * mqp_ende_local\n      * mqp_ende_mq8\n      * mqp_ende_mq8_ff5440\n      * mqp_ende_mq8_ff5440_local\n      * mqp_lm1b_base\n      * mqp_lm1b_h1_ff9984\n      * mqp_lm1b_h2_kv64_ff9984\n      * mqp_lm1b_h4_kv32_ff9984\n      * mqp_lm1b_h8_kv16_ff9984\n      * mqp_lm1b_mq8\n      * mqp_lm1b_mq8_ff9088\n    mtf:\n      * mtf_bitransformer_all_layers_tiny\n      * mtf_bitransformer_base\n      * mtf_bitransformer_tiny\n      * mtf_image_transformer_base\n      * mtf_image_transformer_base_cifar\n      * mtf_image_transformer_base_imagenet\n      * mtf_image_transformer_base_imagenet_mp\n      * mtf_image_transformer_base_imagenet_mp128\n      * mtf_image_transformer_base_imagenet_mp64\n      * mtf_image_transformer_base_imagenet_mp_sp\n      * mtf_image_transformer_base_single\n      * mtf_image_transformer_cifar_4x\n      * mtf_image_transformer_cifar_mp_4x\n      * mtf_image_transformer_length_sharded\n      * mtf_image_transformer_single\n      * mtf_image_transformer_tiny\n      * mtf_image_transformer_tiny_8gpu\n      * mtf_image_transformer_tiny_spatial1d\n      * mtf_image_transformer_tiny_spatial2d\n      * mtf_resnet_base\n      * mtf_resnet_base_cifar\n      * mtf_resnet_base_single\n      * mtf_resnet_single\n      * mtf_resnet_tiny\n      * mtf_transformer_base\n      * mtf_transformer_base_lm\n      * mtf_transformer_enc_single\n      * mtf_transformer_lm_baseline\n      * mtf_transformer_paper_lm_0\n      * mtf_transformer_paper_lm_1\n      * mtf_transformer_paper_lm_2\n      * mtf_transformer_paper_lm_3\n      * mtf_transformer_paper_lm_4\n      * mtf_transformer_paper_lm_5\n      * mtf_transformer_paper_lm_m1\n      * mtf_transformer_paper_tr_0\n      * mtf_transformer_paper_tr_0_a32\n      * mtf_transformer_paper_tr_0_mesh_128\n      * mtf_transformer_paper_tr_0_mesh_512\n      * mtf_transformer_paper_tr_0_mesh_8\n      * mtf_transformer_paper_tr_0_mesh_8_v2\n      * mtf_transformer_paper_tr_0_nf\n      * mtf_transformer_paper_tr_1\n      * mtf_transformer_paper_tr_2\n      * mtf_transformer_paper_tr_3\n      * mtf_transformer_paper_tr_4\n      * mtf_transformer_paper_tr_4_mesh_16_8\n      * mtf_transformer_paper_tr_6_mesh_64_8\n      * mtf_transformer_paper_tr_m1\n      * mtf_transformer_single\n      * mtf_transformer_tiny\n      * mtf_transformer_tiny_8gpu\n      * mtf_transformer_tiny_denoising\n      * mtf_transformer_tiny_lm\n      * mtf_unitransformer_all_layers_tiny\n      * mtf_unitransformer_base\n      * mtf_unitransformer_tiny\n    mtr:\n      * mtr_lm_dense\n      * mtr_lm_dense_0\n      * mtr_lm_dense_0_h1_16\n      * mtr_lm_dense_1\n      * mtr_lm_dense_2\n      * mtr_lm_dense_3\n      * mtr_lm_v1\n      * mtr_lm_v1_h1_8\n      * mtr_tr_dense_0\n      * mtr_tr_dense_0_extra_logit\n      * mtr_tr_dense_0_h16\n      * mtr_tr_dense_0_h1_1\n      * mtr_tr_dense_0_h1_16\n      * mtr_tr_dense_0_h1_8\n      * mtr_tr_dense_0_h2_16\n      * mtr_tr_dense_0_h4\n      * mtr_tr_dense_0_shared_kv\n      * mtr_tr_dense_1\n      * mtr_tr_dense_2\n      * mtr_tr_dense_3\n      * mtr_tr_dense_3_88\n      * mtr_tr_dense_3_fast\n      * mtr_tr_dense_local_0\n      * mtr_tr_dense_local_0_h1_16\n      * mtr_tr_dense_local_0_h1_16_shared\n      * mtr_tr_dense_local_0_h1_16_shared_kv\n      * mtr_tr_dense_local_0_h1_8_kv256\n      * mtr_tr_dense_local_0_w8\n      * mtr_tr_ende_deep\n      * mtr_tr_ende_v0\n      * mtr_tr_enfr_v0\n    neural:\n      * neural_gpu\n    next:\n      * next_frame_ae\n      * next_frame_ae_tiny\n      * next_frame_basic_deterministic\n      * next_frame_basic_recurrent\n      * next_frame_basic_stochastic\n      * next_frame_basic_stochastic_discrete\n      * next_frame_basic_stochastic_discrete_long\n      * next_frame_emily\n      * next_frame_epva\n      * next_frame_glow_bair_qual\n      * next_frame_glow_bair_quant\n      * next_frame_glow_hparams\n      * next_frame_glow_shapes\n      * next_frame_l1\n      * next_frame_l2\n      * next_frame_pixel_noise\n      * next_frame_pixel_noise_long\n      * next_frame_sampling\n      * next_frame_sampling_stochastic\n      * next_frame_savp\n      * next_frame_savp_gan\n      * next_frame_savp_l2\n      * next_frame_savp_vae\n      * next_frame_small\n      * next_frame_sv2p\n      * next_frame_sv2p_atari\n      * next_frame_sv2p_atari_deterministic\n      * next_frame_sv2p_atari_softmax\n      * next_frame_sv2p_atari_softmax_deterministic\n      * next_frame_sv2p_cutoff\n      * next_frame_sv2p_discrete\n      * next_frame_sv2p_tiny\n      * next_frame_sv2p_tiny_external\n      * next_frame_tiny\n      * next_frame_tpu\n    ppo:\n      * ppo_atari_base\n      * ppo_base_v1\n      * ppo_discrete_action_base\n      * ppo_original_params\n      * ppo_original_params_gamma90\n      * ppo_original_params_gamma95\n      * ppo_original_tiny\n      * ppo_original_world_model\n      * ppo_original_world_model_stochastic_discrete\n      * ppo_pong_ae_base\n      * ppo_tiny_world_model\n      * ppo_ttt_params\n    resnet:\n      * resnet_101\n      * resnet_152\n      * resnet_18\n      * resnet_200\n      * resnet_34\n      * resnet_50\n      * resnet_cifar_15\n      * resnet_cifar_32\n      * resnet_cifar_32_td_unit_05_05\n      * resnet_cifar_32_td_unit_no_drop\n      * resnet_cifar_32_td_weight_05_05\n      * resnet_imagenet_102\n      * resnet_imagenet_34\n      * resnet_imagenet_34_td_unit_05_05\n      * resnet_imagenet_34_td_unit_no_drop\n      * resnet_imagenet_34_td_weight_05_05\n    revnet:\n      * revnet_104\n      * revnet_110_cifar\n      * revnet_164_cifar\n      * revnet_38_cifar\n    rlmf:\n      * rlmf_base\n      * rlmf_dqn_tiny\n      * rlmf_eval\n      * rlmf_original\n      * rlmf_tictactoe\n      * rlmf_tiny\n    shake:\n      * shake_shake_quick\n    shakeshake:\n      * shakeshake_big\n      * shakeshake_small\n      * shakeshake_tpu\n    sliced:\n      * sliced_gan\n    slicenet:\n      * slicenet_1\n      * slicenet_1noam\n      * slicenet_1tiny\n    super:\n      * super_lm_b8k\n      * super_lm_base\n      * super_lm_big\n      * super_lm_big_tpu\n      * super_lm_conv\n      * super_lm_high_mix\n      * super_lm_low_mix\n      * super_lm_moe\n      * super_lm_moe_4b_diet\n      * super_lm_moe_h4\n      * super_lm_tpu\n      * super_lm_tpu_memtest\n    text:\n      * text_cnn_base\n    transformer:\n      * transformer_ada_lmpackedbase\n      * transformer_ada_lmpackedbase_dialog\n      * transformer_ada_lmpackedbase_relative\n      * transformer_ae_a3\n      * transformer_ae_a6\n      * transformer_ae_a8\n      * transformer_ae_base\n      * transformer_ae_base_ablation_1\n      * transformer_ae_base_ablation_2\n      * transformer_ae_base_ablation_3\n      * transformer_ae_base_ablation_4\n      * transformer_ae_base_ablation_5\n      * transformer_ae_base_iaf\n      * transformer_ae_base_noatt\n      * transformer_ae_base_tpu\n      * transformer_ae_small\n      * transformer_ae_small_noatt\n      * transformer_base\n      * transformer_base_bs1\n      * transformer_base_bs10\n      * transformer_base_bs2\n      * transformer_base_bs3\n      * transformer_base_bs4\n      * transformer_base_bs5\n      * transformer_base_bs6\n      * transformer_base_bs7\n      * transformer_base_bs8\n      * transformer_base_bs9\n      * transformer_base_multistep8\n      * transformer_base_single_gpu\n      * transformer_base_v1\n      * transformer_base_v2\n      * transformer_base_v3\n      * transformer_base_vq1_16_nb1_packed_dan_b01_scales\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales_dialog\n      * transformer_base_vq_ada_32ex_packed\n      * transformer_big\n      * transformer_big_bs1\n      * transformer_big_dr1\n      * transformer_big_dr2\n      * transformer_big_enfr\n      * transformer_big_enfr_tpu\n      * transformer_big_single_gpu\n      * transformer_big_tpu\n      * transformer_cifar10_memory_v0\n      * transformer_clean\n      * transformer_clean_big\n      * transformer_clean_big_tpu\n      * transformer_common_voice\n      * transformer_common_voice_tpu\n      * transformer_dr0\n      * transformer_dr2\n      * transformer_fairseq_fp16_activation_big\n      * transformer_ff1024\n      * transformer_ff4096\n      * transformer_h1\n      * transformer_h16\n      * transformer_h32\n      * transformer_h4\n      * transformer_hs1024\n      * transformer_hs256\n      * transformer_imagenet64_memory_v0\n      * transformer_k128\n      * transformer_k256\n      * transformer_l10\n      * transformer_l2\n      * transformer_l4\n      * transformer_l8\n      * transformer_librispeech\n      * transformer_librispeech_tpu\n      * transformer_librispeech_tpu_v1\n      * transformer_librispeech_tpu_v2\n      * transformer_librispeech_v1\n      * transformer_librispeech_v2\n      * transformer_lm_tpu_0\n      * transformer_lm_tpu_1\n      * transformer_ls0\n      * transformer_ls2\n      * transformer_mlperf_tpu\n      * transformer_moe_12k\n      * transformer_moe_2k\n      * transformer_moe_8k\n      * transformer_moe_8k_lm\n      * transformer_moe_base\n      * transformer_moe_prepend_8k\n      * transformer_nat_base\n      * transformer_nat_big\n      * transformer_nat_small\n      * transformer_packed_tpu\n      * transformer_parameter_attention_a\n      * transformer_parameter_attention_b\n      * transformer_parsing_base\n      * transformer_parsing_big\n      * transformer_parsing_ice\n      * transformer_prepend\n      * transformer_prepend_v1\n      * transformer_prepend_v2\n      * transformer_relative\n      * transformer_relative_big\n      * transformer_relative_tiny\n      * transformer_revnet_base\n      * transformer_revnet_big\n      * transformer_sketch\n      * transformer_small\n      * transformer_small_tpu\n      * transformer_supervised_attention\n      * transformer_symshard_base\n      * transformer_symshard_h4\n      * transformer_symshard_lm_0\n      * transformer_symshard_sh4\n      * transformer_tall\n      * transformer_tall_big\n      * transformer_tall_finetune_textclass\n      * transformer_tall_finetune_tied\n      * transformer_tall_finetune_uniencdec\n      * transformer_tall_pretrain_lm\n      * transformer_tall_pretrain_lm_tpu\n      * transformer_tall_pretrain_lm_tpu_adafactor\n      * transformer_tall_pretrain_lm_tpu_adafactor_large\n      * transformer_tall_train_tied\n      * transformer_tall_train_uniencdec\n      * transformer_teeny\n      * transformer_test\n      * transformer_timeseries\n      * transformer_timeseries_tpu\n      * transformer_tiny\n      * transformer_tiny_bs1\n      * transformer_tiny_bs2\n      * transformer_tiny_bs3\n      * transformer_tiny_tpu\n      * transformer_topk_16_packed\n      * transformer_tpu\n      * transformer_tpu_1b\n      * transformer_tpu_bf16_activation\n      * transformer_tpu_with_conv\n      * transformer_wikitext103_l16k_memory_v0\n      * transformer_wikitext103_l4k_memory_v0\n      * transformer_wikitext103_l4k_v0\n    universal:\n      * universal_transformer_base\n      * universal_transformer_base_fp16\n      * universal_transformer_base_tpu\n      * universal_transformer_big\n      * universal_transformer_dwa_base\n      * universal_transformer_gru_base\n      * universal_transformer_highway_base\n      * universal_transformer_lstm_base\n      * universal_transformer_lstm_tall\n      * universal_transformer_mix_after_ut_base\n      * universal_transformer_mix_before_ut_base\n      * universal_transformer_position_random_timing_tiny\n      * universal_transformer_position_step_timing_tiny\n      * universal_transformer_sepconv_base\n      * universal_transformer_sepconv_big\n      * universal_transformer_skip_base\n      * universal_transformer_small\n      * universal_transformer_small_dropconnect\n      * universal_transformer_step_sinusoid_timing_tiny\n      * universal_transformer_tall\n      * universal_transformer_teeny\n      * universal_transformer_tiny\n    vqa:\n      * vqa_attention_base\n      * vqa_attention_drop01_dna\n      * vqa_attention_feature_base\n      * vqa_attention_feature_batch1024\n      * vqa_attention_feature_batch1024_dnz\n      * vqa_attention_feature_batch1024_dnz_l2\n      * vqa_attention_feature_batch1024_dnz_noscaledp\n      * vqa_attention_feature_batch1024_drop01\n      * vqa_attention_feature_batch1024_drop01_dna\n      * vqa_attention_feature_batch1024_drop01_dna_concat\n      * vqa_attention_feature_batch1024_lstmlayernorm\n      * vqa_attention_feature_batch1024_numglimps1\n      * vqa_attention_feature_batch512\n      * vqa_attention_feature_dna\n      * vqa_attention_feature_dnz\n      * vqa_attention_feature_dnz_l2\n      * vqa_attention_feature_dnz_noscaledp\n      * vqa_attention_feature_hidden1024\n      * vqa_attention_feature_imagefeat1024\n      * vqa_attention_feature_imagefeat512\n      * vqa_attention_feature_initializer\n      * vqa_attention_feature_lstmlayernorm\n      * vqa_attention_feature_nonormalization\n      * vqa_attention_feature_numglimps1\n      * vqa_attention_numglimps1\n      * vqa_recurrent_self_attention_base\n      * vqa_recurrent_self_attention_big\n      * vqa_recurrent_self_attention_big_l4\n      * vqa_recurrent_self_attention_drop1\n      * vqa_recurrent_self_attention_drop3\n      * vqa_recurrent_self_attention_gru\n      * vqa_recurrent_self_attention_highway\n      * vqa_recurrent_self_attention_l4\n      * vqa_recurrent_self_attention_l8\n      * vqa_recurrent_self_attention_ls2\n      * vqa_recurrent_self_attention_mix_before_ut\n      * vqa_recurrent_self_attention_small\n      * vqa_self_attention_base\n      * vqa_self_attention_feature\n      * vqa_self_attention_feature_batch1024\n      * vqa_self_attention_feature_batch1024_big\n      * vqa_self_attention_feature_batch1024_drop03\n      * vqa_self_attention_feature_batch1024_exp\n      * vqa_self_attention_feature_batch1024_hidden6\n      * vqa_self_attention_feature_batch1024_hidden6_big\n      * vqa_self_attention_feature_lr5\n    wiki:\n      * wiki_2x2_base\n      * wiki_2x2_local\n      * wiki_2x2_v1\n    xception:\n      * xception_base\n      * xception_tiny\n      * xception_tiny_tpu\n    xmoe2:\n      * xmoe2_dense\n      * xmoe2_dense_0\n      * xmoe2_dense_1\n      * xmoe2_dense_2\n      * xmoe2_dense_3\n      * xmoe2_tiny\n      * xmoe2_v1\n      * xmoe2_v1_l4k\n      * xmoe2_v1_l4k_compressed_c4\n      * xmoe2_v1_l4k_compressed_c8\n      * xmoe2_v1_l4k_global_only\n      * xmoe2_v1_l4k_local_only\n      * xmoe2_v1_x128\n    xmoe:\n      * xmoe_2d\n      * xmoe_2d_c15\n      * xmoe_2d_debug\n      * xmoe_2d_x64\n      * xmoe_dense_4k\n      * xmoe_dense_64k\n      * xmoe_dense_8k\n      * xmoe_top_2\n      * xmoe_top_2_c15\n      * xmoe_tr_1d\n      * xmoe_tr_2d\n      * xmoe_tr_dense_2k\n      * xmoe_tr_dense_32k'
Traceback (most recent call last):
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-bleu", line 18, in <module>
    tf.app.run()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/bin/t2t-bleu", line 12, in main
    t2t_bleu.main(argv)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/bin/t2t_bleu.py", line 99, in main
    case_sensitive=False)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensor2tensor/utils/bleu_hook.py", line 205, in bleu_wrapper
    tf.gfile.Open(ref_filename, "r").read()).split("\n")
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 125, in read
    self._preread_check()
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 85, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File "/home/tuna/anaconda3/envs/cloud_prep_convt_june2019/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: /home/tuna/t2t_data/newstest2014.de; No such file or directory
